GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 8 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 2 --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=100, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 8 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 2 --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=100, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 8 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 2 --nepoch 200 --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 8 --log --latency_lambda 5 5 5 5 5 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 2 --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=1, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=100, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 8 --log --latency_lambda 5 5 5 5 5 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 2 --nepoch 200 --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=1, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 8 --log --latency_lambda 5 5 5 5 5 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 2 --nepoch 200 --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=1, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 8 --log --latency_lambda 5 5 5 5 5 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 2 --nepoch 200 --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=1, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 8 --log --latency_lambda 5 5 5 5 5 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 2 --nepoch 200 --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=1, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 8 --log --latency_lambda 5 5 5 5 5 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 2 --nepoch 200 --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=1, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 8 --log --latency_lambda 5 5 5 5 5 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 2 --nepoch 200 --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=1, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 3
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 12 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 3 --nepoch 200 --log
Namespace(batch=12, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=3)

epoch: 101, lr: 0.001	GPU number: 3
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 12 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 3 --nepoch 200 --log
Namespace(batch=12, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=3)

epoch: 101, lr: 0.001	GPU number: 3
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 12 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 3 --nepoch 200 --log
Namespace(batch=12, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=3)

epoch: 101, lr: 0.001	GPU number: 3
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 12 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 3 --nepoch 200 --log
Namespace(batch=12, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=3)

epoch: 101, lr: 0.001	GPU number: 3
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 12 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 3 --nepoch 200 --log
Namespace(batch=12, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=3)

epoch: 101, lr: 0.001	GPU number: 3
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 12 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 3 --nepoch 200 --log
Namespace(batch=12, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=3)

epoch: 101, lr: 0.001	epoch: 102, lr: 0.001	epoch: 103, lr: 0.001	epoch: 104, lr: 0.001	epoch: 105, lr: 0.001	Total loss 4667.777832 (4991.265298)	classification Loss 462.547974 (483.886170)	Localization Loss 4205.229980 (4507.379127)	Take 1609.2891359329224 s
GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 8 --log --latency_lambda 5 5 5 5 5 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 2 --nepoch 200 --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=1, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	epoch: 102, lr: 0.001	epoch: 103, lr: 0.001	epoch: 104, lr: 0.001	epoch: 105, lr: 0.001	Total loss 5091.576172 (4970.180975)	classification Loss 515.616943 (464.508795)	Localization Loss 4575.958984 (4505.672186)	Take 1284.3299310207367 s
GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --batch 8 --log --latency_lambda 5 5 5 5 5 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 2 --nepoch 200 --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=1, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	epoch: 102, lr: 0.001	epoch: 103, lr: 0.001	epoch: 104, lr: 0.001	epoch: 105, lr: 0.001	Total loss 5298.954102 (5142.672468)	classification Loss 633.715820 (548.490750)	Localization Loss 4665.238281 (4594.181713)	Take 904.5095479488373 s
epoch: 106, lr: 0.001	epoch: 107, lr: 0.001	epoch: 108, lr: 0.001	epoch: 109, lr: 0.001	epoch: 110, lr: 0.001	Total loss 3335.482666 (3197.975889)	classification Loss 380.253571 (317.035365)	Localization Loss 2955.229004 (2880.940530)	Take 925.3226225376129 s
epoch: 111, lr: 0.001	epoch: 112, lr: 0.001	epoch: 113, lr: 0.001	epoch: 114, lr: 0.001	epoch: 115, lr: 0.001	Total loss 2777.621094 (2229.214441)	classification Loss 273.903809 (214.412189)	Localization Loss 2503.717285 (2014.802252)	Take 922.4726881980896 s
epoch: 116, lr: 0.001	epoch: 117, lr: 0.001	epoch: 118, lr: 0.001	epoch: 119, lr: 0.001	epoch: 120, lr: 0.001	Total loss 2302.356201 (1908.093877)	classification Loss 219.513809 (168.694929)	Localization Loss 2082.842285 (1739.398947)	Take 1012.4389691352844 s
epoch: 121, lr: 0.001	epoch: 122, lr: 0.001	epoch: 123, lr: 0.001	epoch: 124, lr: 0.001	epoch: 125, lr: 0.001	Total loss 1692.330200 (1606.890492)	classification Loss 146.484375 (135.423299)	Localization Loss 1545.845825 (1471.467192)	Take 2212.231971502304 s
epoch: 126, lr: 0.001	epoch: 127, lr: 0.001	epoch: 128, lr: 0.001	epoch: 129, lr: 0.001	epoch: 130, lr: 0.001	Total loss 1606.703369 (1492.138303)	classification Loss 140.596436 (116.345439)	Localization Loss 1466.106934 (1375.792868)	Take 1481.3898406028748 s
epoch: 131, lr: 0.001	epoch: 132, lr: 0.001	epoch: 133, lr: 0.001	epoch: 134, lr: 0.001	epoch: 135, lr: 0.001	Total loss 1402.829712 (1359.493486)	classification Loss 110.802414 (100.938146)	Localization Loss 1292.027344 (1258.555342)	Take 1469.351542711258 s
epoch: 136, lr: 0.001	epoch: 137, lr: 0.001	epoch: 138, lr: 0.001	epoch: 139, lr: 0.001	epoch: 140, lr: 0.001	Total loss 1302.092773 (1220.198361)	classification Loss 94.401085 (88.166816)	Localization Loss 1207.691650 (1132.031545)	Take 4158.474571943283 s
epoch: 141, lr: 0.001	epoch: 142, lr: 0.001	epoch: 143, lr: 0.001	epoch: 144, lr: 0.001	epoch: 145, lr: 0.001	Total loss 1188.957397 (1109.797377)	classification Loss 104.493523 (79.004144)	Localization Loss 1084.463867 (1030.793234)	Take 2840.487221956253 s
epoch: 146, lr: 0.001	epoch: 147, lr: 0.001	epoch: 148, lr: 0.001	epoch: 149, lr: 0.001	epoch: 150, lr: 0.001	Total loss 1038.699829 (949.994756)	classification Loss 61.585106 (61.155964)	Localization Loss 977.114746 (888.838792)	Take 1143.286295413971 s
epoch: 151, lr: 0.0005	epoch: 152, lr: 0.0005	epoch: 153, lr: 0.0005	epoch: 154, lr: 0.0005	epoch: 155, lr: 0.0005	Total loss 947.022461 (775.006839)	classification Loss 51.862682 (46.479699)	Localization Loss 895.159790 (728.527140)	Take 1156.979130744934 s
epoch: 156, lr: 0.0005	epoch: 157, lr: 0.0005	epoch: 158, lr: 0.0005	epoch: 159, lr: 0.0005	epoch: 160, lr: 0.0005	Total loss 787.853943 (670.865507)	classification Loss 46.743225 (41.659223)	Localization Loss 741.110718 (629.206283)	Take 1347.8452558517456 s
epoch: 161, lr: 0.0005	epoch: 162, lr: 0.0005	epoch: 163, lr: 0.0005	epoch: 164, lr: 0.0005	epoch: 165, lr: 0.0005	Total loss 715.513611 (638.385621)	classification Loss 46.098232 (38.265726)	Localization Loss 669.415405 (600.119895)	Take 1442.0457105636597 s
epoch: 166, lr: 0.0005	epoch: 167, lr: 0.0005	epoch: 168, lr: 0.0005	epoch: 169, lr: 0.0005	epoch: 170, lr: 0.0005	Total loss 832.323486 (761.311000)	classification Loss 38.367706 (37.513788)	Localization Loss 793.955750 (723.797211)	Take 1528.5867257118225 s
epoch: 171, lr: 0.0005	epoch: 172, lr: 0.0005	epoch: 173, lr: 0.0005	epoch: 174, lr: 0.0005	epoch: 175, lr: 0.0005	Total loss 968.367249 (767.691964)	classification Loss 37.597649 (36.282859)	Localization Loss 930.769592 (731.409106)	Take 1523.2591617107391 s
epoch: 176, lr: 0.0005	epoch: 177, lr: 0.0005	epoch: 178, lr: 0.0005	epoch: 179, lr: 0.0005	epoch: 180, lr: 0.0005	Total loss 760.036072 (626.188442)	classification Loss 35.965874 (33.194251)	Localization Loss 724.070190 (592.994191)	Take 1368.22882437706 s
epoch: 181, lr: 0.0005	epoch: 182, lr: 0.0005	epoch: 183, lr: 0.0005	epoch: 184, lr: 0.0005	epoch: 185, lr: 0.0005	Total loss 655.343994 (572.349554)	classification Loss 27.642729 (31.234314)	Localization Loss 627.701294 (541.115239)	Take 1347.3466002941132 s
epoch: 186, lr: 0.0005	epoch: 187, lr: 0.0005	epoch: 188, lr: 0.0005	epoch: 189, lr: 0.0005	epoch: 190, lr: 0.0005	Total loss 768.789612 (699.330565)	classification Loss 29.555004 (30.922664)	Localization Loss 739.234619 (668.407899)	Take 1275.1369893550873 s
epoch: 191, lr: 0.0005	epoch: 192, lr: 0.0005	epoch: 193, lr: 0.0005	epoch: 194, lr: 0.0005	epoch: 195, lr: 0.0005	Total loss 768.917908 (698.857327)	classification Loss 30.088156 (31.207055)	Localization Loss 738.829773 (667.650272)	Take 1288.0281133651733 s
epoch: 196, lr: 0.0005	epoch: 197, lr: 0.0005	epoch: 198, lr: 0.0005	epoch: 199, lr: 0.0005	epoch: 200, lr: 0.0005	Total loss 623.071289 (627.916565)	classification Loss 21.218527 (26.854757)	Localization Loss 601.852783 (601.061808)	Take 1327.8022003173828 s
GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train/l5f3motionnet --nworker 0 --layer 3 --logname latency5forecast3 --batch 8 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --world_size 2 --nepoch 200 --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train/l5f3motionnet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

