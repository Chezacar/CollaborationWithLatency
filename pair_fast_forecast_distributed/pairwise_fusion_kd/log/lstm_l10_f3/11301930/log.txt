GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 20 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 4 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=20, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	epoch: 102, lr: 0.001	epoch: 103, lr: 0.001	epoch: 104, lr: 0.001	epoch: 105, lr: 0.001	Total loss 2408.130127 (1797.932790)	classifieion Loss 3495.497803 (2243.693202)	Localization Loss 33892.511719 (25137.446354)	Forecast Loss 2408.130127 (1797.932861)	Take 929.6365609169006 s
epoch: 106, lr: 0.001	epoch: 107, lr: 0.001	epoch: 108, lr: 0.001	epoch: 109, lr: 0.001	epoch: 110, lr: 0.001	Total loss 2263.423096 (1682.507651)	classifieion Loss 3623.128174 (2237.105703)	Localization Loss 33623.445312 (24975.577629)	Forecast Loss 2263.423096 (1682.507690)	Take 947.6301507949829 s
epoch: 111, lr: 0.001	epoch: 112, lr: 0.001	epoch: 113, lr: 0.001	epoch: 114, lr: 0.001	epoch: 115, lr: 0.001	Total loss 2217.762939 (1637.521011)	classifieion Loss 3605.456299 (2222.467348)	Localization Loss 33244.937500 (24805.650016)	Forecast Loss 2217.762939 (1637.521484)	Take 938.9300193786621 s
epoch: 116, lr: 0.001	epoch: 117, lr: 0.001	epoch: 118, lr: 0.001	epoch: 119, lr: 0.001	epoch: 120, lr: 0.001	Total loss 2161.660156 (1592.623548)	classifieion Loss 3631.975830 (2203.673708)	Localization Loss 32856.500000 (24669.840007)	Forecast Loss 2161.660156 (1592.622681)	Take 1007.1501860618591 s
epoch: 121, lr: 0.001	epoch: 122, lr: 0.001	epoch: 123, lr: 0.001	epoch: 124, lr: 0.001	epoch: 125, lr: 0.001	Total loss 2117.237061 (1558.549499)	classifieion Loss 3637.322998 (2189.611467)	Localization Loss 32565.052734 (24533.834847)	Forecast Loss 2117.237061 (1558.549683)	Take 981.2436602115631 s
epoch: 126, lr: 0.001	epoch: 127, lr: 0.001	epoch: 128, lr: 0.001	epoch: 129, lr: 0.001	epoch: 130, lr: 0.001	Total loss 2080.434814 (1537.619618)	classifieion Loss 3492.703857 (2153.597374)	Localization Loss 32108.759766 (24391.172965)	Forecast Loss 2080.434814 (1537.619873)	Take 978.7773671150208 s
epoch: 131, lr: 0.001	epoch: 132, lr: 0.001	epoch: 133, lr: 0.001	epoch: 134, lr: 0.001	epoch: 135, lr: 0.001	Total loss 2058.660156 (1526.132385)	classifieion Loss 3423.933594 (2107.501598)	Localization Loss 31837.138672 (24272.543424)	Forecast Loss 2058.660156 (1526.132690)	Take 979.0444588661194 s
epoch: 136, lr: 0.001	epoch: 137, lr: 0.001	epoch: 138, lr: 0.001	epoch: 139, lr: 0.001	epoch: 140, lr: 0.001	Total loss 2045.659424 (1512.986161)	classifieion Loss 3427.390625 (2080.799995)	Localization Loss 31768.009766 (24189.083089)	Forecast Loss 2045.659424 (1512.986328)	Take 978.3484389781952 s
epoch: 141, lr: 0.001	epoch: 142, lr: 0.001	epoch: 143, lr: 0.001	epoch: 144, lr: 0.001	epoch: 145, lr: 0.001	Total loss 2036.274170 (1504.936126)	classifieion Loss 3354.738037 (2060.788792)	Localization Loss 31594.380859 (24129.468595)	Forecast Loss 2036.274170 (1504.936279)	Take 997.0706474781036 s
epoch: 146, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 30 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 6 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=30, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 146, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 30 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 6 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=30, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 146, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 30 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 6 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=30, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 146, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 30 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 6 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=30, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 146, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 24 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 4 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=24, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 146, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 24 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 6 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=24, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 146, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 20 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 4 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=20, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 146, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 4 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 146, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 12 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 4 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=12, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 146, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --latency_lambda 5 5 5 5 5 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 20 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 4 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=20, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 146, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 4 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 146, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 4 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 146, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 8 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 2 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 146, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 12 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 2 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=12, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 146, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 12 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 2 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=12, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 146, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 12 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 4 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=12, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 146, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth --batch 8 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 4 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_145.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 146, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_140.pth --batch 8 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 4 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_140.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 141, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_140.pth --batch 4 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930 --world_size 4 --nepoch 400 --port 10044 --forecast_loss True --forecast_model LSTM --log
Namespace(batch=4, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='LSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10044', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l10_f3/11301930/epoch_140.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 141, lr: 0.001	