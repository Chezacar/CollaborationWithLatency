GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435 --world_size 4 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM_l5_f3/12241435', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	epoch: 102, lr: 0.001	epoch: 103, lr: 0.001	epoch: 104, lr: 0.001	epoch: 105, lr: 0.001	Total loss 2305.856201 (1648.374977)	classifieion Loss 1574.918579 (1425.340353)	Localization Loss 65927.062500 (55695.345039)	Forecast Loss 2305.856201 (1648.374878)	Take 839.87730884552 s
epoch: 106, lr: 0.001	epoch: 107, lr: 0.001	epoch: 108, lr: 0.001	epoch: 109, lr: 0.001	epoch: 110, lr: 0.001	Total loss 1447.098389 (1026.687281)	classifieion Loss 1242.192139 (1190.258971)	Localization Loss 65656.953125 (55540.058125)	Forecast Loss 1447.098267 (1026.687012)	Take 913.83278632164 s
epoch: 111, lr: 0.001	epoch: 112, lr: 0.001	epoch: 113, lr: 0.001	epoch: 114, lr: 0.001	epoch: 115, lr: 0.001	Total loss 1122.563843 (875.935082)	classifieion Loss 1061.219727 (1108.172607)	Localization Loss 65911.390625 (55540.136641)	Forecast Loss 1122.563721 (875.935120)	Take 840.5955781936646 s
epoch: 116, lr: 0.001	epoch: 117, lr: 0.001	epoch: 118, lr: 0.001	epoch: 119, lr: 0.001	epoch: 120, lr: 0.001	Total loss 911.369629 (738.469116)	classifieion Loss 855.933167 (1031.717481)	Localization Loss 65872.164062 (55547.981862)	Forecast Loss 911.369568 (738.469238)	Take 813.5795619487762 s
epoch: 121, lr: 0.001	epoch: 122, lr: 0.001	epoch: 123, lr: 0.001	epoch: 124, lr: 0.001	epoch: 125, lr: 0.001	Total loss 822.411499 (675.506681)	classifieion Loss 1029.300293 (983.020367)	Localization Loss 66174.007812 (55532.732461)	Forecast Loss 822.411438 (675.506653)	Take 805.985821723938 s
epoch: 126, lr: 0.001	epoch: 127, lr: 0.001	epoch: 128, lr: 0.001	epoch: 129, lr: 0.001	epoch: 130, lr: 0.001	Total loss 969.286804 (676.161732)	classifieion Loss 1225.523926 (1040.628310)	Localization Loss 66088.453125 (55542.256784)	Forecast Loss 969.286743 (676.161438)	Take 802.8203182220459 s
epoch: 131, lr: 0.001	epoch: 132, lr: 0.001	epoch: 133, lr: 0.001	epoch: 134, lr: 0.001	epoch: 135, lr: 0.001	Total loss 702.365540 (627.580216)	classifieion Loss 1228.610962 (984.427557)	Localization Loss 66134.820312 (55515.342005)	Forecast Loss 702.365479 (627.580139)	Take 796.6177034378052 s
epoch: 136, lr: 0.001	epoch: 137, lr: 0.001	epoch: 138, lr: 0.001	epoch: 139, lr: 0.001	epoch: 140, lr: 0.001	Total loss 713.552063 (624.784297)	classifieion Loss 970.718262 (1084.289062)	Localization Loss 66164.031250 (55551.881615)	Forecast Loss 713.552002 (624.784302)	Take 801.1003699302673 s
epoch: 141, lr: 0.001	epoch: 142, lr: 0.001	epoch: 143, lr: 0.001	epoch: 144, lr: 0.001	epoch: 145, lr: 0.001	Total loss 795.323303 (615.803394)	classifieion Loss 1623.296143 (1002.388523)	Localization Loss 66218.328125 (55529.294779)	Forecast Loss 795.323242 (615.803467)	Take 806.1907076835632 s
epoch: 146, lr: 0.001	epoch: 147, lr: 0.001	epoch: 148, lr: 0.001	epoch: 149, lr: 0.001	epoch: 150, lr: 0.001	Total loss 724.743469 (614.421838)	classifieion Loss 928.336670 (1029.581376)	Localization Loss 65895.468750 (55554.608581)	Forecast Loss 724.743408 (614.421753)	Take 802.4170308113098 s
epoch: 151, lr: 0.001	epoch: 152, lr: 0.001	epoch: 153, lr: 0.001	epoch: 154, lr: 0.001	epoch: 155, lr: 0.001	Total loss 792.791382 (581.681671)	classifieion Loss 997.987549 (1022.195218)	Localization Loss 66022.687500 (55545.793268)	Forecast Loss 792.791321 (581.681702)	Take 788.1534261703491 s
epoch: 156, lr: 0.001	epoch: 157, lr: 0.001	epoch: 158, lr: 0.001	epoch: 159, lr: 0.001	epoch: 160, lr: 0.001	Total loss 689.933838 (588.622853)	classifieion Loss 939.539734 (1039.056674)	Localization Loss 66048.507812 (55559.014414)	Forecast Loss 689.933777 (588.622986)	Take 759.3035082817078 s
epoch: 161, lr: 0.001	epoch: 162, lr: 0.001	epoch: 163, lr: 0.001	epoch: 164, lr: 0.001	epoch: 165, lr: 0.001	Total loss 564.522400 (581.271465)	classifieion Loss 1082.230713 (1027.236871)	Localization Loss 66184.929688 (55547.391992)	Forecast Loss 564.522339 (581.271301)	Take 758.7661509513855 s
epoch: 166, lr: 0.001	epoch: 167, lr: 0.001	epoch: 168, lr: 0.001	epoch: 169, lr: 0.001	epoch: 170, lr: 0.001	Total loss 670.310730 (582.994935)	classifieion Loss 1148.898926 (1008.983985)	Localization Loss 66061.835938 (55544.128737)	Forecast Loss 670.310669 (582.994995)	Take 753.8744897842407 s
epoch: 171, lr: 0.001	epoch: 172, lr: 0.001	epoch: 173, lr: 0.001	epoch: 174, lr: 0.001	epoch: 175, lr: 0.001	Total loss 516.880554 (562.949165)	classifieion Loss 1012.083252 (1023.169877)	Localization Loss 66070.414062 (55551.953529)	Forecast Loss 516.880493 (562.949158)	Take 755.1898312568665 s
epoch: 176, lr: 0.001	epoch: 177, lr: 0.001	epoch: 178, lr: 0.001	epoch: 179, lr: 0.001	epoch: 180, lr: 0.001	Total loss 525.696777 (547.660289)	classifieion Loss 1091.576050 (1000.402020)	Localization Loss 66185.960938 (55543.613021)	Forecast Loss 525.696716 (547.660217)	Take 765.5334959030151 s
epoch: 181, lr: 0.001	epoch: 182, lr: 0.001	epoch: 183, lr: 0.001	epoch: 184, lr: 0.001	epoch: 185, lr: 0.001	Total loss 621.897217 (540.333431)	classifieion Loss 1223.664307 (1015.423985)	Localization Loss 66078.578125 (55543.392760)	Forecast Loss 621.897156 (540.333435)	Take 737.1640520095825 s
epoch: 186, lr: 0.001	epoch: 187, lr: 0.001	epoch: 188, lr: 0.001	epoch: 189, lr: 0.001	epoch: 190, lr: 0.001	Total loss 490.497559 (535.024802)	classifieion Loss 877.671997 (981.439010)	Localization Loss 66035.101562 (55538.514779)	Forecast Loss 490.497498 (535.024536)	Take 727.2378127574921 s
epoch: 191, lr: 0.001	epoch: 192, lr: 0.001	epoch: 193, lr: 0.001	epoch: 194, lr: 0.001	epoch: 195, lr: 0.001	Total loss 562.532959 (517.540324)	classifieion Loss 877.086792 (1028.783865)	Localization Loss 65993.781250 (55545.250208)	Forecast Loss 562.532898 (517.540283)	Take 717.9380605220795 s
epoch: 196, lr: 0.001	epoch: 197, lr: 0.001	epoch: 198, lr: 0.001	epoch: 199, lr: 0.001	epoch: 200, lr: 0.001	Total loss 477.865997 (505.362809)	classifieion Loss 1134.323242 (980.318696)	Localization Loss 66187.093750 (55536.915404)	Forecast Loss 477.865936 (505.362823)	Take 713.1297628879547 s
epoch: 201, lr: 0.001	epoch: 202, lr: 0.001	epoch: 203, lr: 0.001	epoch: 204, lr: 0.001	epoch: 205, lr: 0.001	Total loss 530.860596 (510.582208)	classifieion Loss 1222.037109 (983.850134)	Localization Loss 66302.531250 (55534.876406)	Forecast Loss 530.860535 (510.582306)	Take 728.3918862342834 s
epoch: 206, lr: 0.001	epoch: 207, lr: 0.001	epoch: 208, lr: 0.001	epoch: 209, lr: 0.001	epoch: 210, lr: 0.001	Total loss 466.467590 (496.135065)	classifieion Loss 1163.790771 (981.713349)	Localization Loss 66283.789062 (55537.207500)	Forecast Loss 466.467529 (496.135101)	Take 705.9578881263733 s
epoch: 211, lr: 0.001	epoch: 212, lr: 0.001	epoch: 213, lr: 0.001	epoch: 214, lr: 0.001	epoch: 215, lr: 0.001	Total loss 520.613342 (491.281384)	classifieion Loss 1208.085205 (961.346270)	Localization Loss 66481.968750 (55528.004427)	Forecast Loss 520.613281 (491.281250)	Take 731.9088435173035 s
epoch: 216, lr: 0.001	epoch: 217, lr: 0.001	epoch: 218, lr: 0.001	epoch: 219, lr: 0.001	epoch: 220, lr: 0.001	Total loss 503.626709 (480.442891)	classifieion Loss 1103.712280 (913.306055)	Localization Loss 66207.851562 (55512.237409)	Forecast Loss 503.626648 (480.442657)	Take 728.046368598938 s
epoch: 221, lr: 0.001	epoch: 222, lr: 0.001	epoch: 223, lr: 0.001	epoch: 224, lr: 0.001	epoch: 225, lr: 0.001	Total loss 451.052612 (469.386336)	classifieion Loss 839.662781 (919.526538)	Localization Loss 66105.859375 (55510.343333)	Forecast Loss 451.052551 (469.385986)	Take 707.7061145305634 s
epoch: 226, lr: 0.001	epoch: 227, lr: 0.001	epoch: 228, lr: 0.001	epoch: 229, lr: 0.001	epoch: 230, lr: 0.001	Total loss 444.812714 (461.085732)	classifieion Loss 898.815308 (936.013020)	Localization Loss 66032.531250 (55518.601029)	Forecast Loss 444.812653 (461.085693)	Take 701.808121919632 s
epoch: 231, lr: 0.001	epoch: 232, lr: 0.001	epoch: 233, lr: 0.001	epoch: 234, lr: 0.001	epoch: 235, lr: 0.001	Total loss 458.899261 (455.965420)	classifieion Loss 1008.391418 (916.919722)	Localization Loss 66063.937500 (55518.145690)	Forecast Loss 458.899200 (455.965424)	Take 668.5718724727631 s
epoch: 236, lr: 0.001	epoch: 237, lr: 0.001	epoch: 238, lr: 0.001	epoch: 239, lr: 0.001	epoch: 240, lr: 0.001	Total loss 458.812988 (449.294048)	classifieion Loss 902.872559 (919.972885)	Localization Loss 66248.718750 (55517.296432)	Forecast Loss 458.812927 (449.294128)	Take 444.147745847702 s
epoch: 241, lr: 0.001	epoch: 242, lr: 0.001	epoch: 243, lr: 0.001	epoch: 244, lr: 0.001	epoch: 245, lr: 0.001	Total loss 428.757965 (444.843306)	classifieion Loss 1012.483521 (890.201592)	Localization Loss 66114.890625 (55514.297122)	Forecast Loss 428.757904 (444.843201)	Take 503.0371057987213 s
epoch: 246, lr: 0.001	epoch: 247, lr: 0.001	epoch: 248, lr: 0.001	epoch: 249, lr: 0.001	epoch: 250, lr: 0.001	Total loss 431.449585 (440.360290)	classifieion Loss 881.626099 (951.612411)	Localization Loss 65809.328125 (55519.714102)	Forecast Loss 431.449524 (440.360260)	Take 541.3092136383057 s
epoch: 251, lr: 0.001	epoch: 252, lr: 0.001	epoch: 253, lr: 0.001	epoch: 254, lr: 0.001	epoch: 255, lr: 0.001	Total loss 440.116821 (417.453905)	classifieion Loss 833.935913 (889.664690)	Localization Loss 65928.125000 (55502.379792)	Forecast Loss 440.116760 (417.453827)	Take 456.08412075042725 s
epoch: 256, lr: 0.001	epoch: 257, lr: 0.001	epoch: 258, lr: 0.001	epoch: 259, lr: 0.001	epoch: 260, lr: 0.001	Total loss 417.634399 (417.279730)	classifieion Loss 839.362915 (878.885759)	Localization Loss 65968.710938 (55512.085404)	Forecast Loss 417.634338 (417.279755)	Take 435.70248222351074 s
epoch: 261, lr: 0.001	epoch: 262, lr: 0.001	epoch: 263, lr: 0.001	epoch: 264, lr: 0.001	epoch: 265, lr: 0.001	Total loss 404.074738 (414.425433)	classifieion Loss 891.051392 (876.210873)	Localization Loss 66125.671875 (55492.940586)	Forecast Loss 404.074677 (414.425323)	Take 426.47804856300354 s
epoch: 266, lr: 0.001	epoch: 267, lr: 0.001	epoch: 268, lr: 0.001	epoch: 269, lr: 0.001	epoch: 270, lr: 0.001	Total loss 444.977386 (416.685504)	classifieion Loss 773.384644 (862.239916)	Localization Loss 66053.257812 (55498.009635)	Forecast Loss 444.977325 (416.685364)	Take 434.65591859817505 s
epoch: 271, lr: 0.001	epoch: 272, lr: 0.001	epoch: 273, lr: 0.001	epoch: 274, lr: 0.001	epoch: 275, lr: 0.001	Total loss 421.986176 (396.213837)	classifieion Loss 809.783508 (839.958448)	Localization Loss 66165.531250 (55495.791758)	Forecast Loss 421.986115 (396.213806)	Take 419.2261323928833 s
epoch: 276, lr: 0.001	epoch: 277, lr: 0.001	epoch: 278, lr: 0.001	epoch: 279, lr: 0.001	epoch: 280, lr: 0.001	Total loss 396.050934 (394.866585)	classifieion Loss 783.952148 (828.393914)	Localization Loss 66095.164062 (55497.780326)	Forecast Loss 396.050873 (394.866547)	Take 428.5963065624237 s
epoch: 281, lr: 0.001	epoch: 282, lr: 0.001	epoch: 283, lr: 0.001	epoch: 284, lr: 0.001	epoch: 285, lr: 0.001	Total loss 412.294403 (380.634299)	classifieion Loss 926.786987 (795.482088)	Localization Loss 66101.828125 (55492.616367)	Forecast Loss 412.294342 (380.634216)	Take 436.2829029560089 s
epoch: 286, lr: 0.001	epoch: 287, lr: 0.001	epoch: 288, lr: 0.001	epoch: 289, lr: 0.001	epoch: 290, lr: 0.001	Total loss 388.946899 (373.176339)	classifieion Loss 832.152954 (769.917657)	Localization Loss 65940.890625 (55481.712995)	Forecast Loss 388.946838 (373.176300)	Take 436.53823232650757 s
epoch: 291, lr: 0.001	epoch: 292, lr: 0.001	epoch: 293, lr: 0.001	epoch: 294, lr: 0.001	epoch: 295, lr: 0.001	Total loss 397.752625 (373.628557)	classifieion Loss 780.677673 (781.408738)	Localization Loss 66120.796875 (55476.554766)	Forecast Loss 397.752563 (373.628510)	Take 433.41054248809814 s
epoch: 296, lr: 0.001	epoch: 297, lr: 0.001	epoch: 298, lr: 0.001	epoch: 299, lr: 0.001	epoch: 300, lr: 0.001	Total loss 369.909485 (359.013905)	classifieion Loss 866.967407 (761.978882)	Localization Loss 66041.156250 (55475.617500)	Forecast Loss 369.909424 (359.013733)	Take 433.85532212257385 s
epoch: 301, lr: 0.001	epoch: 302, lr: 0.001	epoch: 303, lr: 0.001	epoch: 304, lr: 0.001	epoch: 305, lr: 0.001	Total loss 363.252228 (356.266374)	classifieion Loss 846.432678 (794.282980)	Localization Loss 65979.054688 (55482.244089)	Forecast Loss 363.252167 (356.266418)	Take 444.394651889801 s
epoch: 306, lr: 0.001	epoch: 307, lr: 0.001	epoch: 308, lr: 0.001	epoch: 309, lr: 0.001	epoch: 310, lr: 0.001	Total loss 366.170746 (362.507457)	classifieion Loss 845.949097 (779.782227)	Localization Loss 66095.398438 (55462.853477)	Forecast Loss 366.170685 (362.507477)	Take 443.7564673423767 s
epoch: 311, lr: 0.001	epoch: 312, lr: 0.001	epoch: 313, lr: 0.001	epoch: 314, lr: 0.001	epoch: 315, lr: 0.001	Total loss 365.591125 (346.033612)	classifieion Loss 791.722107 (748.932367)	Localization Loss 66071.054688 (55473.882669)	Forecast Loss 365.591064 (346.033569)	Take 441.81574177742004 s
epoch: 316, lr: 0.001	epoch: 317, lr: 0.001	epoch: 318, lr: 0.001	epoch: 319, lr: 0.001	epoch: 320, lr: 0.001	Total loss 354.792267 (339.949145)	classifieion Loss 817.409363 (735.742401)	Localization Loss 66081.796875 (55468.294479)	Forecast Loss 354.792206 (339.949097)	Take 436.27936816215515 s
epoch: 321, lr: 0.001	epoch: 322, lr: 0.001	epoch: 323, lr: 0.001	epoch: 324, lr: 0.001	epoch: 325, lr: 0.001	Total loss 379.614929 (335.975214)	classifieion Loss 957.845520 (726.349119)	Localization Loss 66052.304688 (55465.857409)	Forecast Loss 379.614868 (335.975006)	Take 420.8280646800995 s
epoch: 326, lr: 0.001	epoch: 327, lr: 0.001	epoch: 328, lr: 0.001	epoch: 329, lr: 0.001	epoch: 330, lr: 0.001	Total loss 352.703430 (340.310101)	classifieion Loss 793.848877 (695.071203)	Localization Loss 66056.031250 (55450.383138)	Forecast Loss 352.703369 (340.310059)	Take 421.68095088005066 s
epoch: 331, lr: 0.001	epoch: 332, lr: 0.001	epoch: 333, lr: 0.001	epoch: 334, lr: 0.001	epoch: 335, lr: 0.001	Total loss 349.118439 (329.581129)	classifieion Loss 733.123535 (717.728515)	Localization Loss 66048.812500 (55451.932708)	Forecast Loss 349.118378 (329.581055)	Take 459.318806886673 s
epoch: 336, lr: 0.001	epoch: 337, lr: 0.001	epoch: 338, lr: 0.001	epoch: 339, lr: 0.001	epoch: 340, lr: 0.001	Total loss 332.951691 (324.146195)	classifieion Loss 814.027222 (676.139818)	Localization Loss 66083.953125 (55443.346237)	Forecast Loss 332.951630 (324.146149)	Take 522.6979048252106 s
epoch: 341, lr: 0.001	epoch: 342, lr: 0.001	epoch: 343, lr: 0.001	epoch: 344, lr: 0.001	epoch: 345, lr: 0.001	Total loss 348.813690 (314.498139)	classifieion Loss 827.073120 (693.413336)	Localization Loss 66139.796875 (55444.148945)	Forecast Loss 348.813629 (314.498016)	Take 558.3802950382233 s
epoch: 346, lr: 0.001	epoch: 347, lr: 0.001	epoch: 348, lr: 0.001	epoch: 349, lr: 0.001	epoch: 350, lr: 0.001	Total loss 346.757629 (328.735828)	classifieion Loss 792.759644 (718.230206)	Localization Loss 66150.906250 (55435.606250)	Forecast Loss 346.757568 (328.735748)	Take 567.6903266906738 s
epoch: 351, lr: 0.001	epoch: 352, lr: 0.001	epoch: 353, lr: 0.001	epoch: 354, lr: 0.001	epoch: 355, lr: 0.001	Total loss 335.900940 (311.284069)	classifieion Loss 819.257690 (706.413498)	Localization Loss 66004.843750 (55437.446654)	Forecast Loss 335.900879 (311.284088)	Take 632.5932614803314 s
epoch: 356, lr: 0.001	