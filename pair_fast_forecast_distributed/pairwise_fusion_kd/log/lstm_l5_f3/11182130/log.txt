GPU number: 1
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 10 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l5_f3/11182130 --world_size 1 --nepoch 200 --log
Namespace(batch=10, binary=True, data='/GPFS/data/zxlei/dataset/test/train', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l5_f3/11182130', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=1)

epoch: 101, lr: 0.001	epoch: 102, lr: 0.001	epoch: 103, lr: 0.001	epoch: 104, lr: 0.001	epoch: 105, lr: 0.001	Total loss 15161.326172 (20237.192710)	classifieion Loss 758.216919 (819.370444)	Localization Loss 5550.266113 (6888.930483)	Take 3080.1164309978485 s
epoch: 106, lr: 0.001	epoch: 107, lr: 0.001	epoch: 108, lr: 0.001	epoch: 109, lr: 0.001	epoch: 110, lr: 0.001	Total loss 10300.281250 (11172.968810)	classifieion Loss 633.666687 (576.381133)	Localization Loss 4424.108887 (4637.269437)	Take 4042.9296724796295 s
epoch: 111, lr: 0.001	epoch: 112, lr: 0.001	epoch: 113, lr: 0.001	epoch: 114, lr: 0.001	epoch: 115, lr: 0.001	Total loss 9394.373047 (9237.873114)	classifieion Loss 612.409607 (519.877437)	Localization Loss 4293.801758 (4164.721385)	Take 4791.293064117432 s
epoch: 116, lr: 0.001	epoch: 117, lr: 0.001	epoch: 118, lr: 0.001	epoch: 119, lr: 0.001	epoch: 120, lr: 0.001	Total loss 8819.777344 (8179.048782)	classifieion Loss 549.742676 (459.034558)	Localization Loss 4040.583252 (3631.477886)	Take 4820.61542224884 s
epoch: 121, lr: 0.001	epoch: 122, lr: 0.001	epoch: 123, lr: 0.001	epoch: 124, lr: 0.001	epoch: 125, lr: 0.001	Total loss 7146.173340 (6294.930501)	classifieion Loss 376.780762 (299.143122)	Localization Loss 3046.254639 (2601.402398)	Take 5186.549849271774 s
epoch: 126, lr: 0.001	epoch: 127, lr: 0.001	epoch: 128, lr: 0.001	epoch: 129, lr: 0.001	epoch: 130, lr: 0.001	Total loss 6069.879883 (4994.785075)	classifieion Loss 320.180634 (223.607885)	Localization Loss 2608.103760 (2018.771403)	Take 5181.800935268402 s
epoch: 131, lr: 0.001	epoch: 132, lr: 0.001	epoch: 133, lr: 0.001	epoch: 134, lr: 0.001	epoch: 135, lr: 0.001	Total loss 5233.563477 (4257.482143)	classifieion Loss 259.772156 (183.241073)	Localization Loss 2255.363037 (1685.621664)	Take 5698.324905157089 s
epoch: 136, lr: 0.001	epoch: 137, lr: 0.001	epoch: 138, lr: 0.001	epoch: 139, lr: 0.001	epoch: 140, lr: 0.001	Total loss 4215.986328 (3661.243853)	classifieion Loss 159.312256 (150.142487)	Localization Loss 1651.333374 (1419.647836)	Take 7353.709987878799 s
epoch: 141, lr: 0.001	epoch: 142, lr: 0.001	epoch: 143, lr: 0.001	epoch: 144, lr: 0.001	epoch: 145, lr: 0.001	Total loss 3674.811279 (3193.195766)	classifieion Loss 118.155739 (124.784256)	Localization Loss 1374.711426 (1228.101066)	Take 5056.154287099838 s
epoch: 146, lr: 0.001	epoch: 147, lr: 0.001	epoch: 148, lr: 0.001	epoch: 149, lr: 0.001	epoch: 150, lr: 0.001	Total loss 3156.944824 (2802.386519)	classifieion Loss 82.684761 (100.626251)	Localization Loss 1095.289062 (1044.213205)	Take 5978.276916503906 s
epoch: 151, lr: 0.0005	epoch: 152, lr: 0.0005	epoch: 153, lr: 0.0005	epoch: 154, lr: 0.0005	epoch: 155, lr: 0.0005	Total loss 2876.489014 (2506.487746)	classifieion Loss 66.623734 (84.364930)	Localization Loss 950.684204 (918.821678)	Take 4703.157461166382 s
epoch: 156, lr: 0.0005	epoch: 157, lr: 0.0005	epoch: 158, lr: 0.0005	epoch: 159, lr: 0.0005	epoch: 160, lr: 0.0005	Total loss 2733.090332 (2341.006040)	classifieion Loss 68.381889 (76.112635)	Localization Loss 886.511353 (854.328379)	Take 5766.565854310989 s
epoch: 161, lr: 0.0005	epoch: 162, lr: 0.0005	epoch: 163, lr: 0.0005	epoch: 164, lr: 0.0005	epoch: 165, lr: 0.0005	Total loss 2605.246582 (2220.546896)	classifieion Loss 57.017395 (69.262198)	Localization Loss 844.118347 (817.241322)	Take 8352.337382793427 s
epoch: 166, lr: 0.0005	epoch: 167, lr: 0.0005	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 24 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l5_f3/11182130 --world_size 4 --nepoch 200 --log
Namespace(batch=24, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder=True, encoder=True, forecast_loss=True, forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l5_f3/11182130', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10000', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 24 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l5_f3/11182130 --world_size 4 --nepoch 200 --log
Namespace(batch=24, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder=True, encoder=True, forecast_loss=True, forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l5_f3/11182130', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10000', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l5_f3/11182130 --world_size 4 --nepoch 200 --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder=True, encoder=True, forecast_loss=True, forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l5_f3/11182130', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10000', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l5_f3/11182130 --world_size 4 --nepoch 200 --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder=True, encoder=False, forecast_loss=True, forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l5_f3/11182130', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10000', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l5_f3/11182130 --world_size 4 --nepoch 200 --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder=True, encoder=False, forecast_loss=True, forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/lstm_l5_f3/11182130', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10000', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=4)

epoch: 101, lr: 0.001	epoch: 168, lr: 0.0005	epoch: 169, lr: 0.0005	epoch: 170, lr: 0.0005	Total loss 2500.474609 (2114.095583)	classifieion Loss 60.686855 (65.470853)	Localization Loss 796.311646 (777.572488)	Take 8483.151429891586 s
epoch: 171, lr: 0.0005	epoch: 172, lr: 0.0005	epoch: 173, lr: 0.0005	epoch: 174, lr: 0.0005	epoch: 175, lr: 0.0005	Total loss 2378.526855 (2020.473225)	classifieion Loss 59.161854 (61.922166)	Localization Loss 727.207703 (740.399947)	Take 7891.757572650909 s
epoch: 176, lr: 0.0005	epoch: 177, lr: 0.0005	epoch: 178, lr: 0.0005	epoch: 179, lr: 0.0005	epoch: 180, lr: 0.0005	Total loss 2343.437500 (1955.978562)	classifieion Loss 49.228577 (58.508647)	Localization Loss 739.782471 (723.414903)	Take 8075.428587198257 s
epoch: 181, lr: 0.0005	epoch: 182, lr: 0.0005	epoch: 183, lr: 0.0005	epoch: 184, lr: 0.0005	epoch: 185, lr: 0.0005	Total loss 2397.936035 (1908.959272)	classifieion Loss 51.753357 (55.837522)	Localization Loss 831.471375 (716.297004)	Take 6998.9864065647125 s
epoch: 186, lr: 0.0005	epoch: 187, lr: 0.0005	