GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 24 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 6 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=24, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 101, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12151310/epoch_370.pth --batch 30 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 6 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=30, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12151310/epoch_370.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 371, lr: 0.001	epoch: 372, lr: 0.001	epoch: 373, lr: 0.001	epoch: 374, lr: 0.001	epoch: 375, lr: 0.001	Total loss 915.061035 (1465.299005)	classifieion Loss 1384.874390 (1667.797311)	Localization Loss 5087.000000 (5065.060727)	Forecast Loss 915.061035 (1465.299072)	Take 796.729861497879 s
epoch: 376, lr: 0.001	epoch: 377, lr: 0.001	epoch: 378, lr: 0.001	epoch: 379, lr: 0.001	epoch: 380, lr: 0.001	Total loss 799.208801 (1182.735655)	classifieion Loss 1470.307007 (1395.502842)	Localization Loss 5000.076660 (4815.600687)	Forecast Loss 799.208801 (1182.735840)	Take 891.2805182933807 s
epoch: 381, lr: 0.001	epoch: 382, lr: 0.001	epoch: 383, lr: 0.001	epoch: 384, lr: 0.001	epoch: 385, lr: 0.001	Total loss 722.417786 (1025.634597)	classifieion Loss 1333.735352 (1215.413165)	Localization Loss 4883.454102 (4642.173843)	Forecast Loss 722.417786 (1025.634644)	Take 854.1629321575165 s
epoch: 386, lr: 0.001	epoch: 387, lr: 0.001	epoch: 388, lr: 0.001	epoch: 389, lr: 0.001	epoch: 390, lr: 0.001	Total loss 683.936462 (944.068982)	classifieion Loss 1267.422607 (1131.600624)	Localization Loss 4884.536133 (4573.845081)	Forecast Loss 683.936462 (944.068787)	Take 919.3396434783936 s
epoch: 391, lr: 0.001	epoch: 392, lr: 0.001	epoch: 393, lr: 0.001	epoch: 394, lr: 0.001	epoch: 395, lr: 0.001	Total loss 671.627319 (926.375475)	classifieion Loss 1221.645142 (1114.480955)	Localization Loss 4913.644531 (4557.185507)	Forecast Loss 671.627319 (926.375427)	Take 880.073977470398 s
epoch: 396, lr: 0.001	epoch: 397, lr: 0.001	epoch: 398, lr: 0.001	epoch: 399, lr: 0.001	epoch: 400, lr: 0.001	Total loss 637.738708 (876.944539)	classifieion Loss 1266.925171 (1055.338005)	Localization Loss 4912.821289 (4506.508194)	Forecast Loss 637.738708 (876.944458)	Take 830.6669940948486 s
epoch: 401, lr: 0.001	epoch: 402, lr: 0.001	epoch: 403, lr: 0.001	epoch: 404, lr: 0.001	epoch: 405, lr: 0.001	Total loss 607.312439 (833.252789)	classifieion Loss 1200.051758 (1001.512329)	Localization Loss 4879.260254 (4474.039734)	Forecast Loss 607.312439 (833.252747)	Take 780.1460249423981 s
epoch: 406, lr: 0.001	epoch: 407, lr: 0.001	epoch: 408, lr: 0.001	epoch: 409, lr: 0.001	epoch: 410, lr: 0.001	Total loss 577.179321 (788.081917)	classifieion Loss 1043.548828 (938.865666)	Localization Loss 4807.582031 (4437.361801)	Forecast Loss 577.179321 (788.082092)	Take 849.1191987991333 s
epoch: 411, lr: 0.001	epoch: 412, lr: 0.001	epoch: 413, lr: 0.001	epoch: 414, lr: 0.001	epoch: 415, lr: 0.001	Total loss 602.274902 (824.402255)	classifieion Loss 1204.179688 (1005.250173)	Localization Loss 4984.950684 (4483.115262)	Forecast Loss 602.274902 (824.402161)	Take 837.4236450195312 s
epoch: 416, lr: 0.001	epoch: 417, lr: 0.001	epoch: 418, lr: 0.001	epoch: 419, lr: 0.001	epoch: 420, lr: 0.001	Total loss 562.426758 (742.174712)	classifieion Loss 1132.098145 (885.346121)	Localization Loss 4758.427246 (4392.388092)	Forecast Loss 562.426758 (742.174744)	Take 828.1698026657104 s
epoch: 421, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 30 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 6 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=30, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 101, lr: 0.001	epoch: 102, lr: 0.001	epoch: 103, lr: 0.001	epoch: 104, lr: 0.001	epoch: 105, lr: 0.001	Total loss 992.142456 (1713.994063)	classifieion Loss 1304.622314 (1443.953532)	Localization Loss 5367.156250 (5191.014221)	Forecast Loss 992.142456 (1713.994019)	Take 819.2159049510956 s
epoch: 106, lr: 0.001	epoch: 107, lr: 0.001	epoch: 108, lr: 0.001	epoch: 109, lr: 0.001	epoch: 110, lr: 0.001	Total loss 908.483704 (1440.303695)	classifieion Loss 1689.248047 (1517.256516)	Localization Loss 5313.146973 (4994.889685)	Forecast Loss 908.483704 (1440.303589)	Take 799.8457081317902 s
epoch: 111, lr: 0.001	epoch: 112, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 30 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 6 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=30, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 101, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 30 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 6 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=30, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 101, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 30 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 6 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=30, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 101, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 30 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 6 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=30, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 101, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 30 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 6 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=30, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 101, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 30 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 6 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=30, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 101, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 30 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 6 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=30, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 101, lr: 0.001	epoch: 102, lr: 0.001	epoch: 103, lr: 0.001	epoch: 104, lr: 0.001	epoch: 105, lr: 0.001	Total loss 711.060425 (1338.701679)	classifieion Loss 902.750000 (1008.521204)	Localization Loss 4688.999512 (4573.083487)	Forecast Loss 711.060425 (1338.701782)	Take 498.82871890068054 s
epoch: 106, lr: 0.001	epoch: 107, lr: 0.001	epoch: 108, lr: 0.001	epoch: 109, lr: 0.001	epoch: 110, lr: 0.001	Total loss 514.313416 (901.220164)	classifieion Loss 502.413086 (762.466280)	Localization Loss 4406.816406 (4274.966812)	Forecast Loss 514.313416 (901.220032)	Take 437.70832562446594 s
epoch: 111, lr: 0.001	epoch: 112, lr: 0.001	epoch: 113, lr: 0.001	epoch: 114, lr: 0.001	epoch: 115, lr: 0.001	Total loss 434.678650 (742.491447)	classifieion Loss 544.085205 (692.293527)	Localization Loss 4321.005371 (4188.849042)	Forecast Loss 434.678650 (742.491638)	Take 500.83195662498474 s
epoch: 116, lr: 0.001	epoch: 117, lr: 0.001	epoch: 118, lr: 0.001	epoch: 119, lr: 0.001	epoch: 120, lr: 0.001	Total loss 394.050232 (650.313439)	classifieion Loss 517.808960 (656.213031)	Localization Loss 4250.906250 (4146.885022)	Forecast Loss 394.050232 (650.313416)	Take 488.70967292785645 s
epoch: 121, lr: 0.001	epoch: 122, lr: 0.001	epoch: 123, lr: 0.001	epoch: 124, lr: 0.001	epoch: 125, lr: 0.001	Total loss 368.155365 (592.459508)	classifieion Loss 510.627533 (624.969083)	Localization Loss 4220.905273 (4114.748175)	Forecast Loss 368.155365 (592.459534)	Take 478.6735804080963 s
epoch: 126, lr: 0.001	epoch: 127, lr: 0.001	epoch: 128, lr: 0.001	epoch: 129, lr: 0.001	epoch: 130, lr: 0.001	Total loss 347.589233 (545.257701)	classifieion Loss 472.854156 (601.611834)	Localization Loss 4186.589355 (4091.453839)	Forecast Loss 347.589233 (545.257751)	Take 495.7829818725586 s
epoch: 131, lr: 0.001	epoch: 132, lr: 0.001	epoch: 133, lr: 0.001	epoch: 134, lr: 0.001	epoch: 135, lr: 0.001	Total loss 326.525543 (514.946299)	classifieion Loss 461.941254 (585.689324)	Localization Loss 4153.548340 (4085.000467)	Forecast Loss 326.525543 (514.946350)	Take 473.5451273918152 s
epoch: 136, lr: 0.001	epoch: 137, lr: 0.001	epoch: 138, lr: 0.001	epoch: 139, lr: 0.001	epoch: 140, lr: 0.001	Total loss 317.389282 (489.044202)	classifieion Loss 462.218964 (571.147983)	Localization Loss 4170.821777 (4070.905374)	Forecast Loss 317.389282 (489.044250)	Take 463.93425464630127 s
epoch: 141, lr: 0.001	epoch: 142, lr: 0.001	epoch: 143, lr: 0.001	epoch: 144, lr: 0.001	epoch: 145, lr: 0.001	Total loss 306.831726 (473.100241)	classifieion Loss 452.622528 (569.036919)	Localization Loss 4127.153320 (4067.228281)	Forecast Loss 306.831726 (473.100159)	Take 527.8843042850494 s
epoch: 146, lr: 0.001	epoch: 147, lr: 0.001	epoch: 148, lr: 0.001	epoch: 149, lr: 0.001	epoch: 150, lr: 0.001	Total loss 294.113098 (454.874651)	classifieion Loss 441.947083 (559.624884)	Localization Loss 4125.678711 (4062.202209)	Forecast Loss 294.113098 (454.874664)	Take 497.9547929763794 s
epoch: 151, lr: 0.001	epoch: 152, lr: 0.001	epoch: 153, lr: 0.001	epoch: 154, lr: 0.001	epoch: 155, lr: 0.001	Total loss 289.203369 (442.615869)	classifieion Loss 427.869720 (554.366118)	Localization Loss 4118.903320 (4056.776999)	Forecast Loss 289.203369 (442.615784)	Take 493.3904285430908 s
epoch: 156, lr: 0.001	epoch: 157, lr: 0.001	epoch: 158, lr: 0.001	epoch: 159, lr: 0.001	epoch: 160, lr: 0.001	Total loss 283.648895 (432.317733)	classifieion Loss 414.937469 (548.768552)	Localization Loss 4109.127441 (4053.228519)	Forecast Loss 283.648895 (432.317688)	Take 486.4524555206299 s
epoch: 161, lr: 0.001	epoch: 162, lr: 0.001	epoch: 163, lr: 0.001	epoch: 164, lr: 0.001	epoch: 165, lr: 0.001	Total loss 282.758606 (417.266274)	classifieion Loss 429.820129 (544.111514)	Localization Loss 4099.527344 (4047.208035)	Forecast Loss 282.758606 (417.266327)	Take 488.53248286247253 s
epoch: 166, lr: 0.001	epoch: 167, lr: 0.001	epoch: 168, lr: 0.001	epoch: 169, lr: 0.001	epoch: 170, lr: 0.001	Total loss 319.300537 (440.677250)	classifieion Loss 469.054779 (549.645559)	Localization Loss 4128.647949 (4053.890149)	Forecast Loss 319.300537 (440.677216)	Take 512.1958632469177 s
epoch: 171, lr: 0.001	epoch: 172, lr: 0.001	epoch: 173, lr: 0.001	epoch: 174, lr: 0.001	epoch: 175, lr: 0.001	Total loss 269.942627 (403.038078)	classifieion Loss 437.357330 (541.915437)	Localization Loss 4100.183105 (4044.831146)	Forecast Loss 269.942627 (403.038086)	Take 467.8941605091095 s
epoch: 176, lr: 0.001	epoch: 177, lr: 0.001	epoch: 178, lr: 0.001	epoch: 179, lr: 0.001	epoch: 180, lr: 0.001	Total loss 264.229279 (395.558105)	classifieion Loss 429.375153 (537.694771)	Localization Loss 4097.459473 (4039.995920)	Forecast Loss 264.229279 (395.558105)	Take 498.9363491535187 s
epoch: 181, lr: 0.001	epoch: 182, lr: 0.001	epoch: 183, lr: 0.001	epoch: 184, lr: 0.001	epoch: 185, lr: 0.001	Total loss 265.397797 (398.412234)	classifieion Loss 440.805969 (535.277227)	Localization Loss 4116.581543 (4039.732797)	Forecast Loss 265.397797 (398.412262)	Take 445.1465003490448 s
epoch: 186, lr: 0.001	epoch: 187, lr: 0.001	epoch: 188, lr: 0.001	epoch: 189, lr: 0.001	epoch: 190, lr: 0.001	Total loss 259.362457 (386.469072)	classifieion Loss 427.501434 (531.823993)	Localization Loss 4106.266602 (4035.944653)	Forecast Loss 259.362457 (386.469086)	Take 468.6993947029114 s
epoch: 191, lr: 0.001	epoch: 192, lr: 0.001	epoch: 193, lr: 0.001	epoch: 194, lr: 0.001	epoch: 195, lr: 0.001	Total loss 260.290253 (388.591850)	classifieion Loss 437.320465 (535.086445)	Localization Loss 4120.516602 (4040.703494)	Forecast Loss 260.290253 (388.591827)	Take 419.4496829509735 s
epoch: 196, lr: 0.001	epoch: 197, lr: 0.001	epoch: 198, lr: 0.001	epoch: 199, lr: 0.001	epoch: 200, lr: 0.001	Total loss 481.053711 (656.824722)	classifieion Loss 1648.941406 (1361.130144)	Localization Loss 4858.348633 (4492.906552)	Forecast Loss 481.053711 (656.824890)	Take 628.748767375946 s
epoch: 201, lr: 0.001	epoch: 202, lr: 0.001	epoch: 203, lr: 0.001	epoch: 204, lr: 0.001	epoch: 205, lr: 0.001	Total loss 459.665161 (618.491034)	classifieion Loss 1440.547241 (1281.118469)	Localization Loss 4738.228027 (4459.096451)	Forecast Loss 459.665161 (618.490906)	Take 631.9886631965637 s
epoch: 206, lr: 0.001	epoch: 207, lr: 0.001	epoch: 208, lr: 0.001	epoch: 209, lr: 0.001	epoch: 210, lr: 0.001	Total loss 532.138062 (734.542666)	classifieion Loss 826.679688 (1510.626672)	Localization Loss 4727.884277 (4586.362646)	Forecast Loss 532.138062 (734.542542)	Take 655.6732995510101 s
epoch: 211, lr: 0.001	epoch: 212, lr: 0.001	epoch: 213, lr: 0.001	epoch: 214, lr: 0.001	epoch: 215, lr: 0.001	Total loss 516.448914 (702.389698)	classifieion Loss 773.887390 (1356.591602)	Localization Loss 4677.554199 (4547.303229)	Forecast Loss 516.448914 (702.389587)	Take 655.9455354213715 s
epoch: 216, lr: 0.001	epoch: 217, lr: 0.001	epoch: 218, lr: 0.001	epoch: 219, lr: 0.001	epoch: 220, lr: 0.001	Total loss 595.482361 (782.126931)	classifieion Loss 1198.491333 (1441.730202)	Localization Loss 4553.017578 (4595.847772)	Forecast Loss 595.482361 (782.126892)	Take 747.2544002532959 s
epoch: 221, lr: 0.001	epoch: 222, lr: 0.001	epoch: 223, lr: 0.001	epoch: 224, lr: 0.001	epoch: 225, lr: 0.001	Total loss 577.316406 (739.124169)	classifieion Loss 1141.640015 (1301.087098)	Localization Loss 4562.531250 (4546.002118)	Forecast Loss 577.316406 (739.124207)	Take 720.9840438365936 s
epoch: 226, lr: 0.001	epoch: 227, lr: 0.001	epoch: 228, lr: 0.001	epoch: 229, lr: 0.001	epoch: 230, lr: 0.001	Total loss 625.945801 (795.149520)	classifieion Loss 1140.556519 (1326.168789)	Localization Loss 4734.499512 (4607.034372)	Forecast Loss 625.945801 (795.149536)	Take 784.2047803401947 s
epoch: 231, lr: 0.001	epoch: 232, lr: 0.001	epoch: 233, lr: 0.001	epoch: 234, lr: 0.001	epoch: 235, lr: 0.001	Total loss 610.823486 (775.901006)	classifieion Loss 1075.007202 (1229.515957)	Localization Loss 4626.887695 (4574.798370)	Forecast Loss 610.823486 (775.901001)	Take 776.494295835495 s
epoch: 236, lr: 0.001	epoch: 237, lr: 0.001	epoch: 238, lr: 0.001	epoch: 239, lr: 0.001	epoch: 240, lr: 0.001	Total loss 654.062683 (827.906656)	classifieion Loss 960.735291 (1306.300767)	Localization Loss 4705.329102 (4615.118283)	Forecast Loss 654.062683 (827.906555)	Take 829.6198093891144 s
epoch: 241, lr: 0.001	epoch: 242, lr: 0.001	epoch: 243, lr: 0.001	epoch: 244, lr: 0.001	epoch: 245, lr: 0.001	Total loss 635.994751 (806.852614)	classifieion Loss 975.372986 (1226.109481)	Localization Loss 4708.206055 (4587.287689)	Forecast Loss 635.994751 (806.852722)	Take 814.0025098323822 s
epoch: 246, lr: 0.001	epoch: 247, lr: 0.001	epoch: 248, lr: 0.001	epoch: 249, lr: 0.001	epoch: 250, lr: 0.001	GPU number: 5
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 10 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 5 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=10, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=5)

epoch: 101, lr: 0.001	GPU number: 5
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 10 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 5 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=10, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=5)

epoch: 101, lr: 0.001	GPU number: 5
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 10 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 5 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=10, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=5)

epoch: 101, lr: 0.001	GPU number: 5
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 10 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 5 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=10, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=5)

epoch: 101, lr: 0.001	GPU number: 5
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 10 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 5 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=10, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=5)

epoch: 101, lr: 0.001	GPU number: 5
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 10 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 5 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=10, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=5)

epoch: 101, lr: 0.001	GPU number: 5
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 10 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 5 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=10, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=5)

epoch: 101, lr: 0.001	GPU number: 5
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 10 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 5 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=10, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=5)

Total loss 651.619324 (868.109472)	classifieion Loss 1031.377319 (1299.566557)	Localization Loss 4621.609863 (4637.429343)	Forecast Loss 651.619324 (868.109314)	Take 891.0025446414948 s
epoch: 251, lr: 0.001	epoch: 101, lr: 0.001	GPU number: 5
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 10 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 5 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=10, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=5)

epoch: 101, lr: 0.001	GPU number: 5
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 10 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 5 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=10, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=5)

epoch: 101, lr: 0.001	GPU number: 5
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 10 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 5 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=10, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=5)

epoch: 101, lr: 0.001	GPU number: 5
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 10 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 5 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=10, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=5)

epoch: 101, lr: 0.001	GPU number: 5
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 10 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159 --world_size 5 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=10, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=5)

epoch: 101, lr: 0.001	epoch: 252, lr: 0.001	epoch: 102, lr: 0.001	epoch: 253, lr: 0.001	epoch: 103, lr: 0.001	epoch: 104, lr: 0.001	epoch: 254, lr: 0.001	epoch: 105, lr: 0.001	epoch: 255, lr: 0.001	Total loss 507.740723 (401.244358)	classifieion Loss 2799.867676 (1632.773753)	Localization Loss 6284.377441 (4697.903801)	Forecast Loss 507.740723 (401.244354)	Take 719.1015315055847 s
epoch: 106, lr: 0.001	Total loss 624.061646 (825.082850)	classifieion Loss 1014.679688 (1204.442071)	Localization Loss 4558.899414 (4597.499017)	Forecast Loss 624.061646 (825.082947)	Take 864.4435391426086 s
epoch: 256, lr: 0.001	epoch: 107, lr: 0.001	epoch: 257, lr: 0.001	epoch: 108, lr: 0.001	epoch: 109, lr: 0.001	epoch: 258, lr: 0.001	epoch: 110, lr: 0.001	epoch: 259, lr: 0.001	Total loss 618.083557 (562.038916)	classifieion Loss 2566.863281 (2178.367333)	Localization Loss 6480.304688 (4909.605117)	Forecast Loss 618.083557 (562.038879)	Take 788.623176574707 s
epoch: 111, lr: 0.001	epoch: 260, lr: 0.001	epoch: 112, lr: 0.001	Total loss 624.660339 (858.677140)	classifieion Loss 979.463196 (1243.120321)	Localization Loss 4637.469727 (4609.102670)	Forecast Loss 624.660339 (858.677246)	Take 961.1010634899139 s
epoch: 261, lr: 0.001	epoch: 113, lr: 0.001	epoch: 262, lr: 0.001	epoch: 114, lr: 0.001	epoch: 263, lr: 0.001	epoch: 115, lr: 0.001	Total loss 618.083557 (561.912043)	classifieion Loss 2566.863281 (2178.344570)	Localization Loss 6480.304688 (4910.360155)	Forecast Loss 618.083557 (561.911987)	Take 853.7913107872009 s
epoch: 116, lr: 0.001	epoch: 264, lr: 0.001	epoch: 117, lr: 0.001	epoch: 265, lr: 0.001	epoch: 118, lr: 0.001	Total loss 617.056152 (841.360608)	classifieion Loss 967.848083 (1193.284593)	Localization Loss 4623.964844 (4590.289389)	Forecast Loss 617.056152 (841.360535)	Take 956.9155616760254 s
epoch: 266, lr: 0.001	epoch: 119, lr: 0.001	epoch: 267, lr: 0.001	epoch: 120, lr: 0.001	epoch: 268, lr: 0.001	Total loss 558.013733 (666.657879)	classifieion Loss 2770.743164 (2626.969906)	Localization Loss 6296.645020 (4962.111216)	Forecast Loss 558.013733 (666.657837)	Take 946.55153465271 s
epoch: 121, lr: 0.001	epoch: 269, lr: 0.001	epoch: 122, lr: 0.001	epoch: 270, lr: 0.001	epoch: 123, lr: 0.001	Total loss 667.429932 (879.833670)	classifieion Loss 1105.490601 (1180.020337)	Localization Loss 4563.716309 (4609.768832)	Forecast Loss 667.429932 (879.833618)	Take 997.0232419967651 s
epoch: 271, lr: 0.001	epoch: 124, lr: 0.001	epoch: 272, lr: 0.001	epoch: 125, lr: 0.001	epoch: 273, lr: 0.001	Total loss 558.013733 (666.657879)	classifieion Loss 2770.743164 (2626.969906)	Localization Loss 6296.645020 (4962.111216)	Forecast Loss 558.013733 (666.657837)	Take 951.0101692676544 s
epoch: 126, lr: 0.001	epoch: 274, lr: 0.001	epoch: 127, lr: 0.001	epoch: 275, lr: 0.001	epoch: 128, lr: 0.001	Total loss 656.471375 (857.129053)	classifieion Loss 1034.806519 (1134.720482)	Localization Loss 4566.425781 (4583.927908)	Forecast Loss 656.471375 (857.129211)	Take 1014.9996483325958 s
epoch: 276, lr: 0.001	epoch: 129, lr: 0.001	epoch: 277, lr: 0.001	epoch: 130, lr: 0.001	epoch: 278, lr: 0.001	Total loss 561.042114 (731.521962)	classifieion Loss 3444.672363 (2947.769636)	Localization Loss 5908.951172 (5030.600671)	Forecast Loss 561.042114 (731.521973)	Take 1034.8892707824707 s
epoch: 131, lr: 0.001	epoch: 279, lr: 0.001	epoch: 132, lr: 0.001	epoch: 280, lr: 0.001	epoch: 133, lr: 0.001	Total loss 708.951538 (923.997227)	classifieion Loss 782.800720 (1205.777350)	Localization Loss 4414.614746 (4621.204501)	Forecast Loss 708.951538 (923.997192)	Take 1018.7181069850922 s
epoch: 281, lr: 0.001	epoch: 134, lr: 0.001	epoch: 282, lr: 0.001	epoch: 135, lr: 0.001	epoch: 283, lr: 0.001	Total loss 561.042114 (731.521962)	classifieion Loss 3444.672363 (2947.769636)	Localization Loss 5908.951172 (5030.600671)	Forecast Loss 561.042114 (731.521973)	Take 1042.7166640758514 s
epoch: 136, lr: 0.001	epoch: 284, lr: 0.001	epoch: 137, lr: 0.001	epoch: 285, lr: 0.001	epoch: 138, lr: 0.001	Total loss 675.654724 (875.946288)	classifieion Loss 802.182190 (1125.454904)	Localization Loss 4417.556152 (4577.095868)	Forecast Loss 675.654724 (875.946289)	Take 1059.5155341625214 s
epoch: 286, lr: 0.001	epoch: 139, lr: 0.001	epoch: 287, lr: 0.001	epoch: 140, lr: 0.001	epoch: 288, lr: 0.001	epoch: 289, lr: 0.001	epoch: 290, lr: 0.001	Total loss 691.510071 (922.254532)	classifieion Loss 967.785583 (1172.690116)	Localization Loss 4592.258301 (4633.008185)	Forecast Loss 691.510071 (922.254578)	Take 997.6619086265564 s
epoch: 291, lr: 0.001	epoch: 292, lr: 0.001	epoch: 293, lr: 0.001	epoch: 294, lr: 0.001	epoch: 295, lr: 0.001	Total loss 670.328552 (901.046646)	classifieion Loss 861.430298 (1122.421180)	Localization Loss 4484.901855 (4605.651016)	Forecast Loss 670.328552 (901.046570)	Take 1010.9782516956329 s
epoch: 296, lr: 0.001	epoch: 297, lr: 0.001	epoch: 298, lr: 0.001	epoch: 299, lr: 0.001	epoch: 300, lr: 0.001	Total loss 665.150269 (901.879616)	classifieion Loss 1023.392517 (1289.425558)	Localization Loss 4589.075195 (4638.450247)	Forecast Loss 665.150269 (901.879578)	Take 958.6046555042267 s
epoch: 301, lr: 0.001	epoch: 302, lr: 0.001	epoch: 303, lr: 0.001	epoch: 304, lr: 0.001	epoch: 305, lr: 0.001	Total loss 703.279846 (990.786510)	classifieion Loss 989.259949 (1469.161324)	Localization Loss 4579.991211 (4720.487607)	Forecast Loss 703.279846 (990.786560)	Take 1004.547753572464 s
epoch: 306, lr: 0.001	epoch: 307, lr: 0.001	epoch: 308, lr: 0.001	epoch: 309, lr: 0.001	epoch: 310, lr: 0.001	Total loss 622.132202 (792.895892)	classifieion Loss 871.608215 (1130.171375)	Localization Loss 4714.782715 (4572.665988)	Forecast Loss 622.132202 (792.896118)	Take 945.5693116188049 s
epoch: 311, lr: 0.001	epoch: 312, lr: 0.001	epoch: 313, lr: 0.001	epoch: 314, lr: 0.001	epoch: 315, lr: 0.001	Total loss 589.786499 (729.550015)	classifieion Loss 964.574036 (1062.657227)	Localization Loss 4648.216309 (4473.029022)	Forecast Loss 589.786499 (729.549988)	Take 869.6622850894928 s
epoch: 316, lr: 0.001	epoch: 317, lr: 0.001	epoch: 318, lr: 0.001	epoch: 319, lr: 0.001	epoch: 320, lr: 0.001	Total loss 590.766785 (752.195729)	classifieion Loss 841.804321 (1075.571360)	Localization Loss 4650.708008 (4494.384702)	Forecast Loss 590.766785 (752.195801)	Take 886.1248800754547 s
epoch: 321, lr: 0.001	epoch: 322, lr: 0.001	