GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 12 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12182148 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --forecast_model MotionRNN --log
Namespace(batch=12, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='MotionRNN', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12182148', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 24 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12182148 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --forecast_model MotionRNN --log
Namespace(batch=24, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_loss='True', forecast_model='MotionRNN', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12182148', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	epoch: 102, lr: 0.001	epoch: 103, lr: 0.001	epoch: 104, lr: 0.001	epoch: 105, lr: 0.001	Total loss 1339.344849 (1310.242872)	classifieion Loss 958.435730 (1250.164824)	Localization Loss 5134.171875 (4590.526726)	Forecast Loss 1339.344849 (1310.242920)	Take 1492.4662153720856 s
epoch: 106, lr: 0.001	epoch: 107, lr: 0.001	epoch: 108, lr: 0.001	epoch: 109, lr: 0.001	epoch: 110, lr: 0.001	Total loss 1964.834106 (2224.292074)	classifieion Loss 1466.869141 (1778.376526)	Localization Loss 5545.017090 (5294.381316)	Forecast Loss 1964.834106 (2224.291992)	Take 1649.8794667720795 s
epoch: 111, lr: 0.001	epoch: 112, lr: 0.001	epoch: 113, lr: 0.001	epoch: 114, lr: 0.001	epoch: 115, lr: 0.001	Total loss 1221.532837 (1155.154069)	classifieion Loss 1472.777100 (1329.762935)	Localization Loss 5237.855469 (4643.019080)	Forecast Loss 1221.532837 (1155.153931)	Take 1686.1714193820953 s
epoch: 116, lr: 0.001	epoch: 117, lr: 0.001	epoch: 118, lr: 0.001	epoch: 119, lr: 0.001	epoch: 120, lr: 0.001	Total loss 1211.795044 (1185.382231)	classifieion Loss 1358.229370 (1325.354653)	Localization Loss 5432.704590 (4673.292971)	Forecast Loss 1211.795044 (1185.382202)	Take 1734.155195236206 s
epoch: 121, lr: 0.001	epoch: 122, lr: 0.001	epoch: 123, lr: 0.001	epoch: 124, lr: 0.001	epoch: 125, lr: 0.001	Total loss 1144.108398 (1061.607498)	classifieion Loss 1425.307617 (1221.212262)	Localization Loss 5287.463867 (4585.283423)	Forecast Loss 1144.108398 (1061.607422)	Take 1738.395393371582 s
epoch: 126, lr: 0.001	epoch: 127, lr: 0.001	epoch: 128, lr: 0.001	epoch: 129, lr: 0.001	epoch: 130, lr: 0.001	Total loss 1127.442261 (1044.579875)	classifieion Loss 1399.265381 (1186.848188)	Localization Loss 5398.086914 (4583.116907)	Forecast Loss 1127.442261 (1044.579956)	Take 1848.698768377304 s
epoch: 131, lr: 0.001	epoch: 132, lr: 0.001	epoch: 133, lr: 0.001	epoch: 134, lr: 0.001	epoch: 135, lr: 0.001	Total loss 1056.149780 (942.818316)	classifieion Loss 1051.115967 (1019.714891)	Localization Loss 5262.288086 (4470.837134)	Forecast Loss 1056.149780 (942.818237)	Take 1732.3497803211212 s
epoch: 136, lr: 0.001	epoch: 137, lr: 0.001	epoch: 138, lr: 0.001	epoch: 139, lr: 0.001	epoch: 140, lr: 0.001	