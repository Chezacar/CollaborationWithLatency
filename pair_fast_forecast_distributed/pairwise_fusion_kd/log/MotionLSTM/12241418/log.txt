GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 24 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12241418 --world_size 4 --nepoch 400 --port 10029 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=24, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12241418', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10029', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 24 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12241418 --world_size 4 --nepoch 400 --port 10029 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=24, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12241418', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10029', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	epoch: 102, lr: 0.001	epoch: 103, lr: 0.001	epoch: 104, lr: 0.001	epoch: 105, lr: 0.001	Total loss 1894.154053 (1640.901777)	classifieion Loss 1865.941895 (1395.693130)	Localization Loss 6585.689453 (5188.466614)	Forecast Loss 1894.154053 (1640.901489)	Take 733.816680431366 s
epoch: 106, lr: 0.001	epoch: 107, lr: 0.001	epoch: 108, lr: 0.001	epoch: 109, lr: 0.001	epoch: 110, lr: 0.001	Total loss 1656.675415 (1445.657157)	classifieion Loss 1488.173584 (1331.781227)	Localization Loss 6203.081543 (4996.772175)	Forecast Loss 1656.675415 (1445.656982)	Take 835.3461318016052 s
epoch: 111, lr: 0.001	epoch: 112, lr: 0.001	epoch: 113, lr: 0.001	epoch: 114, lr: 0.001	epoch: 115, lr: 0.001	Total loss 1727.753296 (1327.324478)	classifieion Loss 1840.894897 (1296.050722)	Localization Loss 6474.199219 (4887.931348)	Forecast Loss 1727.753296 (1327.324341)	Take 1540.424597978592 s
epoch: 116, lr: 0.001	epoch: 117, lr: 0.001	epoch: 118, lr: 0.001	epoch: 119, lr: 0.001	epoch: 120, lr: 0.001	Total loss 1529.412598 (1252.460590)	classifieion Loss 1470.498901 (1317.071341)	Localization Loss 6175.320312 (4806.454185)	Forecast Loss 1529.412598 (1252.460327)	Take 1653.5520622730255 s
epoch: 121, lr: 0.001	epoch: 122, lr: 0.001	epoch: 123, lr: 0.001	epoch: 124, lr: 0.001	epoch: 125, lr: 0.001	Total loss 1482.436279 (1238.288091)	classifieion Loss 1692.843506 (1330.245226)	Localization Loss 6290.425781 (4807.918804)	Forecast Loss 1482.436279 (1238.288086)	Take 1637.8805646896362 s
epoch: 126, lr: 0.001	epoch: 127, lr: 0.001	epoch: 128, lr: 0.001	epoch: 129, lr: 0.001	epoch: 130, lr: 0.001	Total loss 1444.577881 (1190.454402)	classifieion Loss 1928.754395 (1347.778253)	Localization Loss 6449.104492 (4735.350251)	Forecast Loss 1444.577881 (1190.454468)	Take 1730.1413419246674 s
epoch: 131, lr: 0.001	epoch: 132, lr: 0.001	epoch: 133, lr: 0.001	epoch: 134, lr: 0.001	epoch: 135, lr: 0.001	Total loss 1390.912476 (1174.827921)	classifieion Loss 2208.096680 (1387.235058)	Localization Loss 6343.315430 (4715.907834)	Forecast Loss 1390.912476 (1174.827881)	Take 1732.430615901947 s
epoch: 136, lr: 0.001	epoch: 137, lr: 0.001	epoch: 138, lr: 0.001	epoch: 139, lr: 0.001	epoch: 140, lr: 0.001	Total loss 1450.956055 (1259.138256)	classifieion Loss 1459.523193 (1405.603177)	Localization Loss 6052.321777 (4831.415447)	Forecast Loss 1450.956055 (1259.138184)	Take 1799.4657332897186 s
epoch: 141, lr: 0.001	epoch: 142, lr: 0.001	epoch: 143, lr: 0.001	epoch: 144, lr: 0.001	epoch: 145, lr: 0.001	Total loss 1356.366333 (1185.556502)	classifieion Loss 1648.235107 (1436.108037)	Localization Loss 6010.479492 (4763.198225)	Forecast Loss 1356.366333 (1185.556396)	Take 1802.7460024356842 s
epoch: 146, lr: 0.001	epoch: 147, lr: 0.001	epoch: 148, lr: 0.001	epoch: 149, lr: 0.001	epoch: 150, lr: 0.001	Total loss 1421.701416 (1184.785539)	classifieion Loss 1994.750977 (1509.553794)	Localization Loss 6224.090820 (4764.095916)	Forecast Loss 1421.701416 (1184.785156)	Take 1882.840490102768 s
epoch: 151, lr: 0.001	epoch: 152, lr: 0.001	epoch: 153, lr: 0.001	epoch: 154, lr: 0.001	epoch: 155, lr: 0.001	Total loss 1368.396118 (1146.254203)	classifieion Loss 1899.425049 (1460.852809)	Localization Loss 6084.733398 (4730.422068)	Forecast Loss 1368.396118 (1146.254150)	Take 1898.1969606876373 s
epoch: 156, lr: 0.001	epoch: 157, lr: 0.001	epoch: 158, lr: 0.001	epoch: 159, lr: 0.001	epoch: 160, lr: 0.001	Total loss 1354.142578 (1156.392746)	classifieion Loss 2168.716309 (1466.085496)	Localization Loss 6261.689453 (4754.591748)	Forecast Loss 1354.142578 (1156.392822)	Take 1934.2131876945496 s
epoch: 161, lr: 0.001	epoch: 162, lr: 0.001	epoch: 163, lr: 0.001	epoch: 164, lr: 0.001	epoch: 165, lr: 0.001	Total loss 1293.820435 (1116.897344)	classifieion Loss 1833.256226 (1382.545072)	Localization Loss 6349.877930 (4683.563374)	Forecast Loss 1293.820435 (1116.897339)	Take 1973.0765767097473 s
epoch: 166, lr: 0.001	epoch: 167, lr: 0.001	epoch: 168, lr: 0.001	epoch: 169, lr: 0.001	epoch: 170, lr: 0.001	