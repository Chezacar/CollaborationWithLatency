GPU number: 5
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159/epoch_135.pth --batch 10 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915 --world_size 5 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=10, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159/epoch_135.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=5)

epoch: 136, lr: 0.001	GPU number: 5
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159/epoch_135.pth --batch 10 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915 --world_size 5 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=10, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159/epoch_135.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=5)

epoch: 136, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159/epoch_135.pth --batch 8 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915 --world_size 4 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159/epoch_135.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 136, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159/epoch_135.pth --batch 6 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915 --world_size 6 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=6, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/12292159/epoch_135.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 136, lr: 0.001	epoch: 137, lr: 0.001	epoch: 138, lr: 0.001	epoch: 139, lr: 0.001	epoch: 140, lr: 0.001	Total loss 1804.978271 (825.476391)	classifieion Loss 2784.976074 (3275.809979)	Localization Loss 3664.440918 (5280.518748)	Forecast Loss 1804.978271 (825.476562)	Take 1136.9428851604462 s
epoch: 141, lr: 0.001	epoch: 142, lr: 0.001	epoch: 143, lr: 0.001	epoch: 144, lr: 0.001	epoch: 145, lr: 0.001	Total loss 1804.978271 (825.476391)	classifieion Loss 2784.976074 (3275.809979)	Localization Loss 3664.440918 (5280.518748)	Forecast Loss 1804.978271 (825.476562)	Take 1150.8665597438812 s
epoch: 146, lr: 0.001	epoch: 147, lr: 0.001	epoch: 148, lr: 0.001	epoch: 149, lr: 0.001	epoch: 150, lr: 0.001	Total loss 1881.228882 (865.434592)	classifieion Loss 2382.684814 (3327.704326)	Localization Loss 3290.889893 (5317.882281)	Forecast Loss 1881.228882 (865.434326)	Take 1218.0007770061493 s
epoch: 151, lr: 0.001	epoch: 152, lr: 0.001	epoch: 153, lr: 0.001	epoch: 154, lr: 0.001	epoch: 155, lr: 0.001	Total loss 1881.228882 (865.434592)	classifieion Loss 2382.684814 (3327.704326)	Localization Loss 3290.889893 (5317.882281)	Forecast Loss 1881.228882 (865.434326)	Take 1205.8376557826996 s
epoch: 156, lr: 0.001	epoch: 157, lr: 0.001	epoch: 158, lr: 0.001	epoch: 159, lr: 0.001	epoch: 160, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_155.pth --batch 6 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915 --world_size 6 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=6, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_155.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 156, lr: 0.001	GPU number: 8
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_155.pth --batch 8 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915 --world_size 8 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_155.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=8)

epoch: 156, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_155.pth --batch 4 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915 --world_size 4 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=4, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_155.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 156, lr: 0.001	epoch: 157, lr: 0.001	epoch: 158, lr: 0.001	epoch: 159, lr: 0.001	epoch: 160, lr: 0.001	Total loss 2019.383911 (843.642865)	classifieion Loss 4208.109863 (3203.101826)	Localization Loss 3856.808838 (5322.435573)	Forecast Loss 2019.383911 (843.642700)	Take 1644.2543587684631 s
epoch: 161, lr: 0.001	epoch: 162, lr: 0.001	epoch: 163, lr: 0.001	epoch: 164, lr: 0.001	epoch: 165, lr: 0.001	Total loss 2019.383911 (843.642865)	classifieion Loss 4208.109863 (3203.101826)	Localization Loss 3856.808838 (5322.435573)	Forecast Loss 2019.383911 (843.642700)	Take 1682.2736413478851 s
epoch: 166, lr: 0.001	epoch: 167, lr: 0.001	epoch: 168, lr: 0.001	epoch: 169, lr: 0.001	epoch: 170, lr: 0.001	Total loss 1838.989868 (890.872238)	classifieion Loss 5400.003418 (3313.800028)	Localization Loss 3775.020508 (5335.072758)	Forecast Loss 1838.989868 (890.872437)	Take 1687.9804136753082 s
epoch: 171, lr: 0.001	epoch: 172, lr: 0.001	epoch: 173, lr: 0.001	epoch: 174, lr: 0.001	epoch: 175, lr: 0.001	Total loss 1838.989868 (890.872238)	classifieion Loss 5400.003418 (3313.800028)	Localization Loss 3775.020508 (5335.072758)	Forecast Loss 1838.989868 (890.872437)	Take 1560.55855178833 s
epoch: 176, lr: 0.001	epoch: 177, lr: 0.001	epoch: 178, lr: 0.001	epoch: 179, lr: 0.001	epoch: 180, lr: 0.001	Total loss 1942.849487 (928.479071)	classifieion Loss 6534.558594 (3452.115533)	Localization Loss 4217.160156 (5360.207898)	Forecast Loss 1942.849487 (928.479492)	Take 1650.084897518158 s
epoch: 181, lr: 0.001	epoch: 182, lr: 0.001	epoch: 183, lr: 0.001	epoch: 184, lr: 0.001	epoch: 185, lr: 0.001	Total loss 1942.849487 (928.479071)	classifieion Loss 6534.558594 (3452.115533)	Localization Loss 4217.160156 (5360.207898)	Forecast Loss 1942.849487 (928.479492)	Take 1649.3290753364563 s
epoch: 186, lr: 0.001	epoch: 187, lr: 0.001	epoch: 188, lr: 0.001	epoch: 189, lr: 0.001	epoch: 190, lr: 0.001	Total loss 2104.176270 (962.067091)	classifieion Loss 8107.912109 (3454.298117)	Localization Loss 4429.333008 (5398.010649)	Forecast Loss 2104.176270 (962.067200)	Take 1730.7587220668793 s
epoch: 191, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_190.pth --batch 4 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915 --world_size 4 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=4, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_190.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 191, lr: 0.001	epoch: 192, lr: 0.001	epoch: 193, lr: 0.001	epoch: 194, lr: 0.001	epoch: 195, lr: 0.001	Total loss 2104.176270 (962.067091)	classifieion Loss 8107.912109 (3454.298117)	Localization Loss 4429.333008 (5398.010649)	Forecast Loss 2104.176270 (962.067200)	Take 1747.1473987102509 s
epoch: 196, lr: 0.001	epoch: 197, lr: 0.001	epoch: 198, lr: 0.001	epoch: 199, lr: 0.001	epoch: 200, lr: 0.001	Total loss 1590.494385 (902.830813)	classifieion Loss 4027.797607 (3245.483766)	Localization Loss 3261.468018 (5343.201360)	Forecast Loss 1590.494385 (902.830872)	Take 1765.8023600578308 s
epoch: 201, lr: 0.001	epoch: 202, lr: 0.001	epoch: 203, lr: 0.001	epoch: 204, lr: 0.001	epoch: 205, lr: 0.001	Total loss 1621.201538 (867.715566)	classifieion Loss 3789.364258 (3117.169595)	Localization Loss 3099.021240 (5279.908794)	Forecast Loss 1621.201538 (867.715271)	Take 1263.833218574524 s
epoch: 206, lr: 0.001	epoch: 207, lr: 0.001	epoch: 208, lr: 0.001	epoch: 209, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_205.pth --batch 4 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915 --world_size 4 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=4, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_205.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 206, lr: 0.001	epoch: 207, lr: 0.001	epoch: 208, lr: 0.001	epoch: 209, lr: 0.001	epoch: 210, lr: 0.001	Total loss 500.527924 (596.199459)	classifieion Loss 953.406860 (2319.522886)	Localization Loss 3241.446777 (5078.050742)	Forecast Loss 500.527924 (596.199524)	Take 1403.0577895641327 s
epoch: 211, lr: 0.001	epoch: 212, lr: 0.001	epoch: 213, lr: 0.001	epoch: 214, lr: 0.001	epoch: 215, lr: 0.001	Total loss 343.078949 (465.436158)	classifieion Loss 461.086090 (1845.751018)	Localization Loss 2996.698975 (4968.636359)	Forecast Loss 343.078949 (465.436249)	Take 1595.3707308769226 s
epoch: 216, lr: 0.001	epoch: 217, lr: 0.001	epoch: 218, lr: 0.001	epoch: 219, lr: 0.001	epoch: 220, lr: 0.001	Total loss 1289.473633 (739.135869)	classifieion Loss 2527.594238 (2931.414634)	Localization Loss 3054.363037 (5265.704547)	Forecast Loss 1289.473633 (739.136414)	Take 1353.682712316513 s
epoch: 221, lr: 0.001	epoch: 222, lr: 0.001	epoch: 223, lr: 0.001	epoch: 224, lr: 0.001	epoch: 225, lr: 0.001	Total loss 1668.270264 (748.681515)	classifieion Loss 3196.598389 (2954.772157)	Localization Loss 3425.548828 (5264.503386)	Forecast Loss 1668.270264 (748.681824)	Take 1291.3475031852722 s
epoch: 226, lr: 0.001	epoch: 227, lr: 0.001	epoch: 228, lr: 0.001	epoch: 229, lr: 0.001	epoch: 230, lr: 0.001	Total loss 2202.564941 (931.765721)	classifieion Loss 4933.442871 (3361.924883)	Localization Loss 3209.651611 (5388.707234)	Forecast Loss 2202.564941 (931.765564)	Take 1603.5460324287415 s
epoch: 231, lr: 0.001	epoch: 232, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_230.pth --batch 4 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915 --world_size 4 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=4, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_230.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 231, lr: 0.001	epoch: 232, lr: 0.001	epoch: 233, lr: 0.001	epoch: 234, lr: 0.001	epoch: 235, lr: 0.001	Total loss 131.974213 (460.216372)	classifieion Loss 399.118591 (1843.320936)	Localization Loss 2867.011230 (4969.950335)	Forecast Loss 131.974213 (460.216461)	Take 1649.5992641448975 s
epoch: 236, lr: 0.001	epoch: 237, lr: 0.001	epoch: 238, lr: 0.001	epoch: 239, lr: 0.001	epoch: 240, lr: 0.001	Total loss 743.923279 (515.244595)	classifieion Loss 1547.182617 (2093.085596)	Localization Loss 3087.685547 (4984.033779)	Forecast Loss 743.923279 (515.244873)	Take 1275.2471334934235 s
epoch: 241, lr: 0.001	epoch: 242, lr: 0.001	epoch: 243, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_240.pth --batch 4 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915 --world_size 4 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=4, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_240.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 241, lr: 0.001	epoch: 242, lr: 0.001	epoch: 243, lr: 0.001	epoch: 244, lr: 0.001	epoch: 245, lr: 0.001	Total loss 1619.336670 (732.205448)	classifieion Loss 3489.900391 (2877.122354)	Localization Loss 3270.391113 (5227.986462)	Forecast Loss 1619.336670 (732.205933)	Take 1474.641881942749 s
epoch: 246, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_245.pth --batch 4 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915 --world_size 4 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=4, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_245.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_245.pth --batch 4 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915 --world_size 4 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=4, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01011915/epoch_245.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 246, lr: 0.001	epoch: 247, lr: 0.001	epoch: 248, lr: 0.001	epoch: 249, lr: 0.001	epoch: 250, lr: 0.001	Total loss 2087.631836 (780.891738)	classifieion Loss 4825.092773 (2993.000929)	Localization Loss 3941.902832 (5283.914779)	Forecast Loss 2087.631836 (780.891907)	Take 1540.672376871109 s
epoch: 251, lr: 0.001	epoch: 252, lr: 0.001	epoch: 253, lr: 0.001	epoch: 254, lr: 0.001	epoch: 255, lr: 0.001	Total loss 1622.493408 (739.107370)	classifieion Loss 3506.398438 (2913.645127)	Localization Loss 3261.479004 (5256.056376)	Forecast Loss 1622.493408 (739.107788)	Take 1821.835448026657 s
epoch: 256, lr: 0.001	epoch: 257, lr: 0.001	epoch: 258, lr: 0.001	epoch: 259, lr: 0.001	epoch: 260, lr: 0.001	Total loss 2097.944092 (903.528582)	classifieion Loss 6511.274414 (3225.625360)	Localization Loss 4021.195801 (5309.708930)	Forecast Loss 2097.944092 (903.528748)	Take 1563.1619584560394 s
epoch: 261, lr: 0.001	epoch: 262, lr: 0.001	epoch: 263, lr: 0.001	epoch: 264, lr: 0.001	epoch: 265, lr: 0.001	Total loss 329.737915 (433.630873)	classifieion Loss 477.707550 (1742.100793)	Localization Loss 2978.982178 (4928.606984)	Forecast Loss 329.737915 (433.630981)	Take 1535.4242255687714 s
epoch: 266, lr: 0.001	epoch: 267, lr: 0.001	epoch: 268, lr: 0.001	epoch: 269, lr: 0.001	epoch: 270, lr: 0.001	Total loss 492.163818 (546.868262)	classifieion Loss 986.099243 (2095.279354)	Localization Loss 3260.588867 (5013.535995)	Forecast Loss 492.163818 (546.868286)	Take 1565.0222096443176 s
epoch: 271, lr: 0.001	epoch: 272, lr: 0.001	epoch: 273, lr: 0.001	epoch: 274, lr: 0.001	epoch: 275, lr: 0.001	Total loss 1620.724487 (774.468465)	classifieion Loss 3077.219971 (2924.735766)	Localization Loss 3216.251465 (5246.084606)	Forecast Loss 1620.724487 (774.468506)	Take 1797.0260603427887 s
epoch: 276, lr: 0.001	epoch: 277, lr: 0.001	epoch: 278, lr: 0.001	epoch: 279, lr: 0.001	epoch: 280, lr: 0.001	Total loss 136.295044 (613.218916)	classifieion Loss 412.817444 (2413.878518)	Localization Loss 2866.899414 (5114.531942)	Forecast Loss 136.295044 (613.218628)	Take 1458.078886270523 s
epoch: 281, lr: 0.001	epoch: 282, lr: 0.001	epoch: 283, lr: 0.001	epoch: 284, lr: 0.001	epoch: 285, lr: 0.001	Total loss 1444.953003 (763.077001)	classifieion Loss 2997.495117 (2918.509338)	Localization Loss 3126.183838 (5281.926429)	Forecast Loss 1444.953003 (763.077393)	Take 1446.6377403736115 s
epoch: 286, lr: 0.001	epoch: 287, lr: 0.001	epoch: 288, lr: 0.001	epoch: 289, lr: 0.001	epoch: 290, lr: 0.001	Total loss 1455.557007 (728.461484)	classifieion Loss 2578.663574 (2834.608151)	Localization Loss 3625.529541 (5196.570145)	Forecast Loss 1455.557007 (728.461182)	Take 1269.8460042476654 s
epoch: 291, lr: 0.001	epoch: 292, lr: 0.001	epoch: 293, lr: 0.001	epoch: 294, lr: 0.001	epoch: 295, lr: 0.001	Total loss 2006.261841 (778.398869)	classifieion Loss 4787.798828 (2993.791415)	Localization Loss 4014.356934 (5283.761240)	Forecast Loss 2006.261841 (778.399109)	Take 1461.0839836597443 s
epoch: 296, lr: 0.001	epoch: 297, lr: 0.001	epoch: 298, lr: 0.001	epoch: 299, lr: 0.001	epoch: 300, lr: 0.001	Total loss 497.429932 (437.625194)	classifieion Loss 984.528198 (1807.034236)	Localization Loss 3244.397461 (4933.553119)	Forecast Loss 497.429932 (437.625153)	Take 1397.4831953048706 s
epoch: 301, lr: 0.001	epoch: 302, lr: 0.001	epoch: 303, lr: 0.001	epoch: 304, lr: 0.001	epoch: 305, lr: 0.001	Total loss 1433.432251 (705.433065)	classifieion Loss 3072.562744 (2638.670052)	Localization Loss 3157.961426 (5209.064429)	Forecast Loss 1433.432251 (705.433472)	Take 1201.4288129806519 s
epoch: 306, lr: 0.001	epoch: 307, lr: 0.001	epoch: 308, lr: 0.001	epoch: 309, lr: 0.001	epoch: 310, lr: 0.001	Total loss 809.172546 (587.592607)	classifieion Loss 2759.912109 (2350.116522)	Localization Loss 3520.442871 (5087.863523)	Forecast Loss 809.172546 (587.592834)	Take 1503.1198406219482 s
epoch: 311, lr: 0.001	epoch: 312, lr: 0.001	epoch: 313, lr: 0.001	epoch: 314, lr: 0.001	epoch: 315, lr: 0.001	Total loss 1354.450562 (802.253450)	classifieion Loss 3706.767578 (2955.210290)	Localization Loss 3025.167236 (5270.437587)	Forecast Loss 1354.450562 (802.253296)	Take 1589.588380098343 s
epoch: 316, lr: 0.001	epoch: 317, lr: 0.001	epoch: 318, lr: 0.001	epoch: 319, lr: 0.001	epoch: 320, lr: 0.001	Total loss 1976.651245 (811.444646)	classifieion Loss 4517.026367 (3057.807470)	Localization Loss 3553.427246 (5282.093042)	Forecast Loss 1976.651245 (811.444519)	Take 1636.2570304870605 s
epoch: 321, lr: 0.001	epoch: 322, lr: 0.001	epoch: 323, lr: 0.001	epoch: 324, lr: 0.001	epoch: 325, lr: 0.001	Total loss 1430.835693 (825.180685)	classifieion Loss 4774.720703 (2964.606824)	Localization Loss 3193.344238 (5279.754496)	Forecast Loss 1430.835693 (825.180725)	Take 1357.60325050354 s
epoch: 326, lr: 0.001	epoch: 327, lr: 0.001	epoch: 328, lr: 0.001	epoch: 329, lr: 0.001	epoch: 330, lr: 0.001	Total loss 309.783295 (486.201055)	classifieion Loss 396.208069 (1999.448246)	Localization Loss 2973.806885 (4981.151370)	Forecast Loss 309.783295 (486.201324)	Take 1586.6539943218231 s
epoch: 331, lr: 0.001	epoch: 332, lr: 0.001	epoch: 333, lr: 0.001	epoch: 334, lr: 0.001	epoch: 335, lr: 0.001	Total loss 1818.687988 (737.182225)	classifieion Loss 4787.853027 (2865.374574)	Localization Loss 3334.277832 (5249.705771)	Forecast Loss 1818.687988 (737.182556)	Take 1533.8306651115417 s
epoch: 336, lr: 0.001	epoch: 337, lr: 0.001	epoch: 338, lr: 0.001	epoch: 339, lr: 0.001	epoch: 340, lr: 0.001	Total loss 601.779785 (637.372293)	classifieion Loss 515.878296 (2422.971700)	Localization Loss 3126.339355 (5115.811248)	Forecast Loss 601.779785 (637.372009)	Take 1546.3798525333405 s
epoch: 341, lr: 0.001	epoch: 342, lr: 0.001	epoch: 343, lr: 0.001	epoch: 344, lr: 0.001	epoch: 345, lr: 0.001	Total loss 420.941772 (545.669116)	classifieion Loss 1298.182617 (2074.479495)	Localization Loss 3125.219238 (5017.926323)	Forecast Loss 420.941772 (545.668945)	Take 1284.4173538684845 s
epoch: 346, lr: 0.001	epoch: 347, lr: 0.001	epoch: 348, lr: 0.001	epoch: 349, lr: 0.001	epoch: 350, lr: 0.001	Total loss 728.265625 (748.805973)	classifieion Loss 2689.978516 (2889.452066)	Localization Loss 3560.462891 (5226.897506)	Forecast Loss 728.265625 (748.805664)	Take 1462.2563681602478 s
epoch: 351, lr: 0.001	epoch: 352, lr: 0.001	epoch: 353, lr: 0.001	epoch: 354, lr: 0.001	epoch: 355, lr: 0.001	Total loss 1851.634766 (820.949605)	classifieion Loss 6410.070312 (2891.208574)	Localization Loss 3585.266602 (5243.199181)	Forecast Loss 1851.634766 (820.949707)	Take 1419.3708264827728 s
epoch: 356, lr: 0.001	epoch: 357, lr: 0.001	epoch: 358, lr: 0.001	epoch: 359, lr: 0.001	epoch: 360, lr: 0.001	Total loss 324.471832 (543.664936)	classifieion Loss 481.700226 (2044.161933)	Localization Loss 2992.952148 (5013.127177)	Forecast Loss 324.471832 (543.664917)	Take 1660.3728153705597 s
epoch: 361, lr: 0.001	epoch: 362, lr: 0.001	epoch: 363, lr: 0.001	epoch: 364, lr: 0.001	epoch: 365, lr: 0.001	Total loss 397.105225 (666.453928)	classifieion Loss 409.041718 (2580.560248)	Localization Loss 2956.724609 (5135.169602)	Forecast Loss 397.105225 (666.454041)	Take 1593.1135413646698 s
epoch: 366, lr: 0.001	epoch: 367, lr: 0.001	epoch: 368, lr: 0.001	epoch: 369, lr: 0.001	epoch: 370, lr: 0.001	Total loss 1644.826416 (787.256739)	classifieion Loss 4867.302734 (2853.228003)	Localization Loss 3365.717529 (5225.585480)	Forecast Loss 1644.826416 (787.256714)	Take 1337.3079662322998 s
epoch: 371, lr: 0.001	epoch: 372, lr: 0.001	epoch: 373, lr: 0.001	epoch: 374, lr: 0.001	epoch: 375, lr: 0.001	Total loss 1933.635010 (898.577730)	classifieion Loss 6336.164062 (3190.979900)	Localization Loss 4081.853760 (5304.811705)	Forecast Loss 1933.635010 (898.578064)	Take 1603.8686456680298 s
epoch: 376, lr: 0.001	epoch: 377, lr: 0.001	epoch: 378, lr: 0.001	epoch: 379, lr: 0.001	epoch: 380, lr: 0.001	Total loss 1693.241699 (705.751294)	classifieion Loss 3795.868164 (2749.062042)	Localization Loss 3485.040527 (5230.034997)	Forecast Loss 1693.241699 (705.751709)	Take 1485.277470588684 s
epoch: 381, lr: 0.001	epoch: 382, lr: 0.001	epoch: 383, lr: 0.001	epoch: 384, lr: 0.001	epoch: 385, lr: 0.001	Total loss 1168.450562 (631.972729)	classifieion Loss 3144.471680 (2448.557457)	Localization Loss 3541.885742 (5115.101990)	Forecast Loss 1168.450562 (631.972412)	Take 1640.252048254013 s
epoch: 386, lr: 0.001	epoch: 387, lr: 0.001	epoch: 388, lr: 0.001	epoch: 389, lr: 0.001	epoch: 390, lr: 0.001	Total loss 577.013428 (682.546698)	classifieion Loss 657.423462 (2588.712091)	Localization Loss 3188.312500 (5160.245263)	Forecast Loss 577.013428 (682.546814)	Take 1575.1062664985657 s
epoch: 391, lr: 0.001	epoch: 392, lr: 0.001	epoch: 393, lr: 0.001	epoch: 394, lr: 0.001	epoch: 395, lr: 0.001	Total loss 1320.105103 (794.956475)	classifieion Loss 3039.498047 (2968.467012)	Localization Loss 2847.627441 (5278.687667)	Forecast Loss 1320.105103 (794.956482)	Take 1787.1446771621704 s
epoch: 396, lr: 0.001	epoch: 397, lr: 0.001	epoch: 398, lr: 0.001	epoch: 399, lr: 0.001	epoch: 400, lr: 0.001	Total loss 703.515747 (529.403062)	classifieion Loss 1094.311279 (2164.978493)	Localization Loss 3270.863281 (5018.097140)	Forecast Loss 703.515747 (529.403442)	Take 1433.6603910923004 s
epoch: 401, lr: 0.001	epoch: 402, lr: 0.001	epoch: 403, lr: 0.001	epoch: 404, lr: 0.001	epoch: 405, lr: 0.001	Total loss 371.637756 (731.286497)	classifieion Loss 568.419800 (2830.172034)	Localization Loss 2984.873047 (5211.208658)	Forecast Loss 371.637756 (731.286255)	Take 1323.630878686905 s
epoch: 406, lr: 0.001	epoch: 407, lr: 0.001	epoch: 408, lr: 0.001	epoch: 409, lr: 0.001	epoch: 410, lr: 0.001	Total loss 1681.700928 (855.171039)	classifieion Loss 3035.337402 (3187.311127)	Localization Loss 3315.231934 (5340.850717)	Forecast Loss 1681.700928 (855.171204)	Take 1444.60551071167 s
epoch: 411, lr: 0.001	epoch: 412, lr: 0.001	epoch: 413, lr: 0.001	epoch: 414, lr: 0.001	epoch: 415, lr: 0.001	Total loss 1638.082520 (839.722970)	classifieion Loss 4561.233887 (2955.365492)	Localization Loss 3285.790527 (5276.282586)	Forecast Loss 1638.082520 (839.722717)	Take 1342.6609268188477 s
epoch: 416, lr: 0.001	epoch: 417, lr: 0.001	epoch: 418, lr: 0.001	epoch: 419, lr: 0.001	epoch: 420, lr: 0.001	Total loss 809.172546 (585.544555)	classifieion Loss 2759.912109 (2339.311721)	Localization Loss 3520.442871 (5083.040997)	Forecast Loss 809.172546 (585.544739)	Take 1317.4721596240997 s
epoch: 421, lr: 0.001	epoch: 422, lr: 0.001	epoch: 423, lr: 0.001	epoch: 424, lr: 0.001	epoch: 425, lr: 0.001	Total loss 1823.664795 (718.929017)	classifieion Loss 4885.726562 (2766.139449)	Localization Loss 3390.695312 (5239.122189)	Forecast Loss 1823.664795 (718.929565)	Take 1377.3153314590454 s
epoch: 426, lr: 0.001	epoch: 427, lr: 0.001	epoch: 428, lr: 0.001	epoch: 429, lr: 0.001	epoch: 430, lr: 0.001	Total loss 1957.557007 (886.875957)	classifieion Loss 6537.487793 (3182.786381)	Localization Loss 3886.423096 (5278.054752)	Forecast Loss 1957.557007 (886.875671)	Take 1633.8384022712708 s
epoch: 431, lr: 0.001	epoch: 432, lr: 0.001	epoch: 433, lr: 0.001	epoch: 434, lr: 0.001	epoch: 435, lr: 0.001	Total loss 1966.010864 (942.908369)	classifieion Loss 6963.734863 (3350.846353)	Localization Loss 4406.234863 (5352.909656)	Forecast Loss 1966.010864 (942.908264)	Take 1522.0637576580048 s
epoch: 436, lr: 0.001	epoch: 437, lr: 0.001	epoch: 438, lr: 0.001	epoch: 439, lr: 0.001	epoch: 440, lr: 0.001	Total loss 1564.282593 (884.028066)	classifieion Loss 2926.680176 (3205.827602)	Localization Loss 3015.626953 (5365.677158)	Forecast Loss 1564.282593 (884.028259)	Take 1507.3593101501465 s
epoch: 441, lr: 0.001	epoch: 442, lr: 0.001	epoch: 443, lr: 0.001	epoch: 444, lr: 0.001	epoch: 445, lr: 0.001	Total loss 1912.447754 (839.973294)	classifieion Loss 3690.523926 (3245.464786)	Localization Loss 4004.316895 (5351.075520)	Forecast Loss 1912.447754 (839.973877)	Take 1694.9501836299896 s
epoch: 446, lr: 0.001	epoch: 447, lr: 0.001	epoch: 448, lr: 0.001	epoch: 449, lr: 0.001	epoch: 450, lr: 0.001	Total loss 1697.586548 (890.494219)	classifieion Loss 4365.159180 (3133.654029)	Localization Loss 3222.273926 (5283.473215)	Forecast Loss 1697.586548 (890.493958)	Take 1589.9595720767975 s
epoch: 451, lr: 0.001	epoch: 452, lr: 0.001	epoch: 453, lr: 0.001	epoch: 454, lr: 0.001	epoch: 455, lr: 0.001	Total loss 1629.744141 (788.080796)	classifieion Loss 3249.110596 (3013.890739)	Localization Loss 3471.262695 (5278.468539)	Forecast Loss 1629.744141 (788.081238)	Take 1292.746491909027 s
epoch: 456, lr: 0.001	epoch: 457, lr: 0.001	epoch: 458, lr: 0.001	epoch: 459, lr: 0.001	epoch: 460, lr: 0.001	Total loss 556.630981 (447.821644)	classifieion Loss 1417.379150 (1810.791472)	Localization Loss 2831.390381 (4948.878609)	Forecast Loss 556.630981 (447.821686)	Take 1511.0150978565216 s
epoch: 461, lr: 0.001	epoch: 462, lr: 0.001	epoch: 463, lr: 0.001	epoch: 464, lr: 0.001	epoch: 465, lr: 0.001	Total loss 582.279480 (571.063160)	classifieion Loss 646.984619 (2253.717433)	Localization Loss 3155.719971 (5065.539647)	Forecast Loss 582.279480 (571.063477)	Take 1511.5998134613037 s
epoch: 466, lr: 0.001	epoch: 467, lr: 0.001	epoch: 468, lr: 0.001	epoch: 469, lr: 0.001	epoch: 470, lr: 0.001	Total loss 426.207886 (433.647652)	classifieion Loss 1280.237061 (1779.867528)	Localization Loss 3109.638916 (4928.536897)	Forecast Loss 426.207886 (433.647522)	Take 1307.5812697410583 s
epoch: 471, lr: 0.001	epoch: 472, lr: 0.001	epoch: 473, lr: 0.001	epoch: 474, lr: 0.001	epoch: 475, lr: 0.001	Total loss 559.729004 (606.796630)	classifieion Loss 1345.956787 (2359.029920)	Localization Loss 2833.651367 (5089.330118)	Forecast Loss 559.729004 (606.796570)	Take 1330.4138748645782 s
epoch: 476, lr: 0.001	epoch: 477, lr: 0.001	epoch: 478, lr: 0.001	epoch: 479, lr: 0.001	epoch: 480, lr: 0.001	Total loss 377.215393 (694.686482)	classifieion Loss 1208.792114 (2669.269668)	Localization Loss 2950.305420 (5143.137196)	Forecast Loss 377.215393 (694.686218)	Take 1336.2574594020844 s
