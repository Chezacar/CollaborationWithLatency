GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 4 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715 --world_size 4 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=4, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 4 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715 --world_size 4 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=4, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 4 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715 --world_size 4 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=4, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 4 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715 --world_size 4 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=4, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 4 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715 --world_size 4 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=4, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 8 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715 --world_size 4 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 12 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715 --world_size 4 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=12, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 12 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715 --world_size 6 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=12, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 101, lr: 0.001	epoch: 102, lr: 0.001	epoch: 103, lr: 0.001	epoch: 104, lr: 0.001	epoch: 105, lr: 0.001	Total loss 437.983582 (416.802806)	classifieion Loss 2785.092041 (1647.637821)	Localization Loss 5937.357422 (4622.051576)	Forecast Loss 437.983582 (416.802795)	Take 742.1847558021545 s
epoch: 106, lr: 0.001	epoch: 107, lr: 0.001	epoch: 108, lr: 0.001	epoch: 109, lr: 0.001	epoch: 110, lr: 0.001	Total loss 578.179688 (548.510463)	classifieion Loss 2748.846680 (2118.020512)	Localization Loss 5571.780273 (4702.361526)	Forecast Loss 578.179688 (548.510498)	Take 771.3963034152985 s
epoch: 111, lr: 0.001	epoch: 112, lr: 0.001	epoch: 113, lr: 0.001	epoch: 114, lr: 0.001	epoch: 115, lr: 0.001	Total loss 571.437134 (531.644221)	classifieion Loss 2633.584473 (2017.190603)	Localization Loss 5661.585938 (4734.867716)	Forecast Loss 571.437134 (531.644165)	Take 778.3411648273468 s
epoch: 116, lr: 0.001	epoch: 117, lr: 0.001	epoch: 118, lr: 0.001	epoch: 119, lr: 0.001	epoch: 120, lr: 0.001	Total loss 723.063477 (560.385156)	classifieion Loss 3317.835693 (1908.231117)	Localization Loss 5379.458008 (4703.495859)	Forecast Loss 723.063477 (560.385132)	Take 834.1402747631073 s
epoch: 121, lr: 0.001	epoch: 122, lr: 0.001	epoch: 123, lr: 0.001	epoch: 124, lr: 0.001	epoch: 125, lr: 0.001	Total loss 669.424927 (519.027217)	classifieion Loss 2641.518799 (1587.888989)	Localization Loss 5272.701660 (4609.780737)	Forecast Loss 669.424927 (519.027161)	Take 861.0359945297241 s
epoch: 126, lr: 0.001	epoch: 127, lr: 0.001	epoch: 128, lr: 0.001	epoch: 129, lr: 0.001	epoch: 130, lr: 0.001	Total loss 568.443420 (549.082031)	classifieion Loss 1560.083008 (1310.778607)	Localization Loss 5045.954102 (4564.762995)	Forecast Loss 568.443420 (549.081970)	Take 916.3755285739899 s
epoch: 131, lr: 0.001	epoch: 132, lr: 0.001	epoch: 133, lr: 0.001	epoch: 134, lr: 0.001	epoch: 135, lr: 0.001	Total loss 515.403442 (492.152077)	classifieion Loss 1601.801514 (1137.229851)	Localization Loss 5027.224609 (4435.793590)	Forecast Loss 515.403442 (492.152130)	Take 905.131098985672 s
epoch: 136, lr: 0.001	epoch: 137, lr: 0.001	epoch: 138, lr: 0.001	epoch: 139, lr: 0.001	epoch: 140, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715/epoch_135.pth --batch 4 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715 --world_size 4 --nepoch 500 --port 10043 --forecast_loss True --forecast_model MotionLSTM --log
Namespace(batch=4, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='True', encoder='False', forecast_KD='False', forecast_loss='True', forecast_model='MotionLSTM', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715', lr=0.001, mode='train', model_only=False, nepoch=500, ngpus_per_node=2, nworker=0, only_det=True, port='10043', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/MotionLSTM/01171715/epoch_135.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=4)

epoch: 136, lr: 0.001	epoch: 137, lr: 0.001	epoch: 138, lr: 0.001	epoch: 139, lr: 0.001	epoch: 140, lr: 0.001	Total loss 1294.886230 (515.472758)	classifieion Loss 422.958191 (1256.160005)	Localization Loss 3054.440186 (4827.639462)	Forecast Loss 1294.886230 (515.472473)	Take 1567.167959690094 s
epoch: 141, lr: 0.001	epoch: 142, lr: 0.001	epoch: 143, lr: 0.001	epoch: 144, lr: 0.001	epoch: 145, lr: 0.001	Total loss 1203.587646 (443.279816)	classifieion Loss 417.757446 (1035.536313)	Localization Loss 2982.114014 (4650.364723)	Forecast Loss 1203.587646 (443.279480)	Take 1442.4826192855835 s
epoch: 146, lr: 0.001	epoch: 147, lr: 0.001	epoch: 148, lr: 0.001	epoch: 149, lr: 0.001	epoch: 150, lr: 0.001	Total loss 1195.144043 (489.093847)	classifieion Loss 419.285034 (1173.057915)	Localization Loss 2907.938477 (4801.642787)	Forecast Loss 1195.144043 (489.094025)	Take 1599.108633518219 s
epoch: 151, lr: 0.001	epoch: 152, lr: 0.001	epoch: 153, lr: 0.001	epoch: 154, lr: 0.001	epoch: 155, lr: 0.001	Total loss 1066.581421 (412.210681)	classifieion Loss 389.985535 (911.924551)	Localization Loss 2920.536133 (4605.412598)	Forecast Loss 1066.581421 (412.210571)	Take 1510.0501673221588 s
epoch: 156, lr: 0.001	epoch: 157, lr: 0.001	epoch: 158, lr: 0.001	epoch: 159, lr: 0.001	epoch: 160, lr: 0.001	Total loss 1083.573486 (474.902803)	classifieion Loss 542.763916 (1082.846230)	Localization Loss 2907.617920 (4738.531676)	Forecast Loss 1083.573486 (474.902863)	Take 1531.683801651001 s
epoch: 161, lr: 0.001	epoch: 162, lr: 0.001	epoch: 163, lr: 0.001	epoch: 164, lr: 0.001	epoch: 165, lr: 0.001	Total loss 969.952026 (395.569574)	classifieion Loss 472.124329 (852.288266)	Localization Loss 2796.895996 (4564.781429)	Forecast Loss 969.952026 (395.569427)	Take 1759.9166526794434 s
epoch: 166, lr: 0.001	epoch: 167, lr: 0.001	epoch: 168, lr: 0.001	epoch: 169, lr: 0.001	epoch: 170, lr: 0.001	Total loss 986.858643 (460.116998)	classifieion Loss 467.471313 (1059.038796)	Localization Loss 2853.053467 (4726.925741)	Forecast Loss 986.858643 (460.117035)	Take 1824.4854114055634 s
epoch: 171, lr: 0.001	epoch: 172, lr: 0.001	epoch: 173, lr: 0.001	epoch: 174, lr: 0.001	epoch: 175, lr: 0.001	Total loss 897.099976 (414.022985)	classifieion Loss 426.961426 (882.880908)	Localization Loss 2794.468506 (4600.498224)	Forecast Loss 897.099976 (414.022827)	Take 1703.2602553367615 s
epoch: 176, lr: 0.001	epoch: 177, lr: 0.001	epoch: 178, lr: 0.001	epoch: 179, lr: 0.001	epoch: 180, lr: 0.001	Total loss 956.312500 (444.488245)	classifieion Loss 453.221313 (1056.922433)	Localization Loss 2811.239502 (4702.376934)	Forecast Loss 956.312500 (444.488434)	Take 1976.479454278946 s
epoch: 181, lr: 0.001	epoch: 182, lr: 0.001	epoch: 183, lr: 0.001	epoch: 184, lr: 0.001	epoch: 185, lr: 0.001	Total loss 857.713989 (374.525192)	classifieion Loss 443.857117 (826.423042)	Localization Loss 2758.116699 (4556.941890)	Forecast Loss 857.713989 (374.525299)	Take 1995.7867164611816 s
epoch: 186, lr: 0.001	epoch: 187, lr: 0.001	epoch: 188, lr: 0.001	epoch: 189, lr: 0.001	epoch: 190, lr: 0.001	Total loss 891.071106 (446.075266)	classifieion Loss 469.694397 (1068.776597)	Localization Loss 2832.718994 (4707.166141)	Forecast Loss 891.071106 (446.075439)	Take 1755.8013191223145 s
epoch: 191, lr: 0.001	epoch: 192, lr: 0.001	epoch: 193, lr: 0.001	epoch: 194, lr: 0.001	epoch: 195, lr: 0.001	Total loss 793.976440 (367.489386)	classifieion Loss 376.498627 (848.595169)	Localization Loss 2730.383057 (4562.534533)	Forecast Loss 793.976440 (367.489410)	Take 1744.3441817760468 s
epoch: 196, lr: 0.001	epoch: 197, lr: 0.001	epoch: 198, lr: 0.001	epoch: 199, lr: 0.001	epoch: 200, lr: 0.001	Total loss 124.656090 (498.089540)	classifieion Loss 429.400482 (1753.292194)	Localization Loss 2845.546875 (4956.367632)	Forecast Loss 124.656090 (498.089478)	Take 1295.883044242859 s
epoch: 201, lr: 0.001	epoch: 202, lr: 0.001	epoch: 203, lr: 0.001	epoch: 204, lr: 0.001	epoch: 205, lr: 0.001	Total loss 398.524231 (496.663833)	classifieion Loss 328.854126 (1508.365204)	Localization Loss 2931.770508 (4852.914644)	Forecast Loss 398.524231 (496.663696)	Take 1800.725403547287 s
epoch: 206, lr: 0.001	epoch: 207, lr: 0.001	epoch: 208, lr: 0.001	epoch: 209, lr: 0.001	epoch: 210, lr: 0.001	Total loss 919.946716 (433.048259)	classifieion Loss 385.072662 (1019.422345)	Localization Loss 2731.571289 (4699.977949)	Forecast Loss 919.946716 (433.048187)	Take 1751.1937429904938 s
epoch: 211, lr: 0.001	epoch: 212, lr: 0.001	epoch: 213, lr: 0.001	epoch: 214, lr: 0.001	epoch: 215, lr: 0.001	Total loss 292.349487 (410.999094)	classifieion Loss 344.464233 (1597.775037)	Localization Loss 2828.555664 (4877.951554)	Forecast Loss 292.349487 (410.999176)	Take 1596.5413393974304 s
epoch: 216, lr: 0.001	epoch: 217, lr: 0.001	epoch: 218, lr: 0.001	epoch: 219, lr: 0.001	epoch: 220, lr: 0.001	Total loss 224.105896 (481.057679)	classifieion Loss 471.342834 (1385.676327)	Localization Loss 2854.513672 (4821.366021)	Forecast Loss 224.105896 (481.057617)	Take 1804.1333367824554 s
epoch: 221, lr: 0.001	epoch: 222, lr: 0.001	epoch: 223, lr: 0.001	epoch: 224, lr: 0.001	epoch: 225, lr: 0.001	Total loss 220.907745 (425.905826)	classifieion Loss 429.617615 (1455.351669)	Localization Loss 2839.485840 (4845.957160)	Forecast Loss 220.907745 (425.905701)	Take 1683.6928420066833 s
epoch: 226, lr: 0.001	epoch: 227, lr: 0.001	epoch: 228, lr: 0.001	epoch: 229, lr: 0.001	epoch: 230, lr: 0.001	Total loss 579.489807 (437.577925)	classifieion Loss 434.394104 (1149.331686)	Localization Loss 2807.048340 (4755.118605)	Forecast Loss 579.489807 (437.577972)	Take 1535.5185945034027 s
epoch: 231, lr: 0.001	epoch: 232, lr: 0.001	epoch: 233, lr: 0.001	epoch: 234, lr: 0.001	epoch: 235, lr: 0.001	Total loss 836.089050 (434.539069)	classifieion Loss 1140.786011 (1150.875883)	Localization Loss 3262.642578 (4733.559571)	Forecast Loss 836.089050 (434.539276)	Take 1588.6061177253723 s
epoch: 236, lr: 0.001	epoch: 237, lr: 0.001	epoch: 238, lr: 0.001	epoch: 239, lr: 0.001	epoch: 240, lr: 0.001	Total loss 402.608215 (416.868727)	classifieion Loss 382.448364 (1325.622864)	Localization Loss 2903.694580 (4780.733129)	Forecast Loss 402.608215 (416.868774)	Take 1653.6964740753174 s
epoch: 241, lr: 0.001	epoch: 242, lr: 0.001	epoch: 243, lr: 0.001	epoch: 244, lr: 0.001	epoch: 245, lr: 0.001	Total loss 214.626923 (422.595122)	classifieion Loss 393.311371 (1444.745432)	Localization Loss 2854.715088 (4842.271650)	Forecast Loss 214.626923 (422.595032)	Take 1567.7150359153748 s
epoch: 246, lr: 0.001	epoch: 247, lr: 0.001	epoch: 248, lr: 0.001	epoch: 249, lr: 0.001	epoch: 250, lr: 0.001	Total loss 794.663696 (390.476139)	classifieion Loss 380.547485 (903.406098)	Localization Loss 2706.110352 (4625.442997)	Forecast Loss 794.663696 (390.475861)	Take 1622.7008345127106 s
epoch: 251, lr: 0.001	epoch: 252, lr: 0.001	epoch: 253, lr: 0.001	epoch: 254, lr: 0.001	epoch: 255, lr: 0.001	Total loss 337.755768 (409.963421)	classifieion Loss 375.589020 (1324.285493)	Localization Loss 2843.064453 (4762.113799)	Forecast Loss 337.755768 (409.963501)	Take 1565.9932692050934 s
epoch: 256, lr: 0.001	epoch: 257, lr: 0.001	epoch: 258, lr: 0.001	epoch: 259, lr: 0.001	epoch: 260, lr: 0.001	Total loss 619.889282 (406.860582)	classifieion Loss 435.474182 (1119.750386)	Localization Loss 2776.694824 (4731.378834)	Forecast Loss 619.889282 (406.860748)	Take 1897.361317873001 s
epoch: 261, lr: 0.001	epoch: 262, lr: 0.001	epoch: 263, lr: 0.001	epoch: 264, lr: 0.001	epoch: 265, lr: 0.001	Total loss 759.615967 (420.024292)	classifieion Loss 403.197113 (976.557353)	Localization Loss 2774.630127 (4650.895601)	Forecast Loss 759.615967 (420.024170)	Take 1597.3169085979462 s
epoch: 266, lr: 0.001	epoch: 267, lr: 0.001	epoch: 268, lr: 0.001	epoch: 269, lr: 0.001	epoch: 270, lr: 0.001	Total loss 202.787888 (472.751414)	classifieion Loss 399.077362 (1426.977065)	Localization Loss 2847.075684 (4815.896425)	Forecast Loss 202.787888 (472.751465)	Take 1525.060587644577 s
epoch: 271, lr: 0.001	epoch: 272, lr: 0.001	epoch: 273, lr: 0.001	epoch: 274, lr: 0.001	epoch: 275, lr: 0.001	Total loss 802.796753 (395.426401)	classifieion Loss 398.421112 (950.164011)	Localization Loss 2729.730469 (4630.736040)	Forecast Loss 802.796753 (395.426147)	Take 1587.4096312522888 s
epoch: 276, lr: 0.001	epoch: 277, lr: 0.001	epoch: 278, lr: 0.001	epoch: 279, lr: 0.001	epoch: 280, lr: 0.001	Total loss 860.533447 (416.977500)	classifieion Loss 885.447571 (1129.886052)	Localization Loss 3043.786133 (4701.938454)	Forecast Loss 860.533447 (416.977509)	Take 2044.5210754871368 s
epoch: 281, lr: 0.001	epoch: 282, lr: 0.001	epoch: 283, lr: 0.001	epoch: 284, lr: 0.001	epoch: 285, lr: 0.001	Total loss 636.169434 (395.491157)	classifieion Loss 387.317566 (1178.603565)	Localization Loss 2737.638672 (4723.760220)	Forecast Loss 636.169434 (395.491028)	Take 1687.897602558136 s
epoch: 286, lr: 0.001	epoch: 287, lr: 0.001	epoch: 288, lr: 0.001	epoch: 289, lr: 0.001	epoch: 290, lr: 0.001	Total loss 757.086914 (376.659562)	classifieion Loss 401.757843 (875.612621)	Localization Loss 2683.506348 (4577.117564)	Forecast Loss 757.086914 (376.659424)	Take 1592.8788692951202 s
epoch: 291, lr: 0.001	epoch: 292, lr: 0.001	epoch: 293, lr: 0.001	epoch: 294, lr: 0.001	epoch: 295, lr: 0.001	Total loss 274.371521 (421.728362)	classifieion Loss 365.924133 (1544.504777)	Localization Loss 2840.157715 (4861.527655)	Forecast Loss 274.371521 (421.728333)	Take 1419.4688830375671 s
epoch: 296, lr: 0.001	epoch: 297, lr: 0.001	epoch: 298, lr: 0.001	epoch: 299, lr: 0.001	epoch: 300, lr: 0.001	Total loss 583.449280 (382.137678)	classifieion Loss 412.647095 (923.956525)	Localization Loss 2753.784180 (4626.212077)	Forecast Loss 583.449280 (382.137787)	Take 1444.8160450458527 s
epoch: 301, lr: 0.001	epoch: 302, lr: 0.001	epoch: 303, lr: 0.001	epoch: 304, lr: 0.001	epoch: 305, lr: 0.001	Total loss 592.786804 (376.502699)	classifieion Loss 401.678772 (985.245679)	Localization Loss 2761.259766 (4630.097513)	Forecast Loss 592.786804 (376.502747)	Take 1512.4598531723022 s
epoch: 306, lr: 0.001	epoch: 307, lr: 0.001	epoch: 308, lr: 0.001	epoch: 309, lr: 0.001	epoch: 310, lr: 0.001	Total loss 214.410721 (456.705719)	classifieion Loss 412.452759 (1420.788762)	Localization Loss 2899.980957 (4795.821960)	Forecast Loss 214.410721 (456.705475)	Take 1654.1301054954529 s
epoch: 311, lr: 0.001	epoch: 312, lr: 0.001	epoch: 313, lr: 0.001	epoch: 314, lr: 0.001	epoch: 315, lr: 0.001	Total loss 209.383896 (454.734036)	classifieion Loss 410.358521 (1359.311205)	Localization Loss 2893.401855 (4773.636221)	Forecast Loss 209.383896 (454.734131)	Take 1428.0256538391113 s
epoch: 316, lr: 0.001	epoch: 317, lr: 0.001	epoch: 318, lr: 0.001	epoch: 319, lr: 0.001	epoch: 320, lr: 0.001	Total loss 557.904053 (388.297984)	classifieion Loss 433.818848 (995.045928)	Localization Loss 2836.552246 (4651.932139)	Forecast Loss 557.904053 (388.298065)	Take 1637.4239008426666 s
epoch: 321, lr: 0.001	epoch: 322, lr: 0.001	epoch: 323, lr: 0.001	epoch: 324, lr: 0.001	epoch: 325, lr: 0.001	