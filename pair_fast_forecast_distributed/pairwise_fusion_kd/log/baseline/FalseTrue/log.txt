GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 32 --log --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 200 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=32, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder=True, encoder=True, forecast_loss=True, forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 24 --log --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 200 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=24, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder=True, encoder=True, forecast_loss=True, forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 16 --log --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 200 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=16, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder=True, encoder=True, forecast_loss=True, forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 12 --log --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 200 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=12, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder=True, encoder=True, forecast_loss=True, forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 12 --log --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 200 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=12, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder=True, encoder=True, forecast_loss=True, forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 12 --log --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 200 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=12, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder=True, encoder=True, forecast_loss=True, forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 12 --log --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 200 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=12, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder=True, encoder=True, forecast_loss=True, forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 12 --log --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 200 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=12, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder=True, encoder=True, forecast_loss=True, forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 12 --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 200 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=12, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder=True, encoder=True, forecast_loss=True, forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 12 --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 200 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=12, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder=True, encoder=True, forecast_loss=True, forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 12 --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 200 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=12, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='False', forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 24 --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 200 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=24, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='False', forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 48 --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 4 --nepoch 200 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=48, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='False', forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=200, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=4)

epoch: 101, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 96 --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 4 --nepoch 300 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=96, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='False', forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=300, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=4)

epoch: 101, lr: 0.001	epoch: 102, lr: 0.001	epoch: 103, lr: 0.001	epoch: 104, lr: 0.001	epoch: 105, lr: 0.001	Total loss 1672.020264 (1617.105290)	classifieion Loss 185.556641 (181.675623)	Localization Loss 1486.463623 (1435.429665)	Take 2015.6365394592285 s
epoch: 106, lr: 0.001	epoch: 107, lr: 0.001	epoch: 108, lr: 0.001	epoch: 109, lr: 0.001	epoch: 110, lr: 0.001	Total loss 1140.378174 (1084.291046)	classifieion Loss 110.675995 (110.162042)	Localization Loss 1029.702148 (974.129006)	Take 2091.5786712169647 s
epoch: 111, lr: 0.001	epoch: 112, lr: 0.001	epoch: 113, lr: 0.001	epoch: 114, lr: 0.001	epoch: 115, lr: 0.001	Total loss 1015.268433 (904.543263)	classifieion Loss 80.070587 (78.630359)	Localization Loss 935.197876 (825.912907)	Take 2160.6011867523193 s
epoch: 116, lr: 0.001	epoch: 117, lr: 0.001	epoch: 118, lr: 0.001	epoch: 119, lr: 0.001	epoch: 120, lr: 0.001	Total loss 945.121277 (858.176784)	classifieion Loss 59.017822 (61.998650)	Localization Loss 886.103455 (796.178136)	Take 2111.606565952301 s
epoch: 121, lr: 0.001	epoch: 122, lr: 0.001	epoch: 123, lr: 0.001	epoch: 124, lr: 0.001	epoch: 125, lr: 0.001	Total loss 775.188049 (780.265374)	classifieion Loss 45.798042 (51.911442)	Localization Loss 729.390015 (728.353937)	Take 1859.8639063835144 s
epoch: 126, lr: 0.001	epoch: 127, lr: 0.001	epoch: 128, lr: 0.001	epoch: 129, lr: 0.001	epoch: 130, lr: 0.001	Total loss 663.846863 (603.336233)	classifieion Loss 38.088997 (43.954068)	Localization Loss 625.757874 (559.382168)	Take 3497.57733297348 s
epoch: 131, lr: 0.001	epoch: 132, lr: 0.001	epoch: 133, lr: 0.001	epoch: 134, lr: 0.001	epoch: 135, lr: 0.001	Total loss 1014.701477 (752.955198)	classifieion Loss 35.201962 (40.535000)	Localization Loss 979.499512 (712.420199)	Take 3721.970411300659 s
epoch: 136, lr: 0.001	epoch: 137, lr: 0.001	epoch: 138, lr: 0.001	epoch: 139, lr: 0.001	epoch: 140, lr: 0.001	Total loss 733.168823 (658.940954)	classifieion Loss 30.073723 (36.107219)	Localization Loss 703.095093 (622.833738)	Take 3860.0829260349274 s
epoch: 141, lr: 0.001	epoch: 142, lr: 0.001	epoch: 143, lr: 0.001	epoch: 144, lr: 0.001	epoch: 145, lr: 0.001	Total loss 569.453308 (564.617044)	classifieion Loss 27.165581 (33.697927)	Localization Loss 542.287720 (530.919119)	Take 3736.9502317905426 s
epoch: 146, lr: 0.001	epoch: 147, lr: 0.001	epoch: 148, lr: 0.001	epoch: 149, lr: 0.001	epoch: 150, lr: 0.001	Total loss 728.099426 (618.859094)	classifieion Loss 27.956112 (32.297557)	Localization Loss 700.143311 (586.561537)	Take 3639.978499174118 s
epoch: 151, lr: 0.0005	epoch: 152, lr: 0.0005	epoch: 153, lr: 0.0005	GPU number: 4
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue/epoch_150.pth --batch 96 --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 4 --nepoch 300 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=96, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='False', forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=300, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue/epoch_150.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=4)

epoch: 151, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue/epoch_150.pth --batch 24 --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 4 --nepoch 300 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=24, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='False', forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=300, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue/epoch_150.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=4)

epoch: 151, lr: 0.001	GPU number: 4
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue/epoch_150.pth --batch 24 --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 4 --nepoch 300 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=24, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='False', forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=300, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue/epoch_150.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=4)

epoch: 151, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue/epoch_150.pth --batch 12 --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 300 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=12, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='False', forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=300, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue/epoch_150.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 151, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue/epoch_150.pth --batch 12 --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 300 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=12, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='False', forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=300, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue/epoch_150.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 151, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue/epoch_150.pth --batch 36 --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 300 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=36, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='False', forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=300, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue/epoch_150.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 151, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue/epoch_150.pth --batch 36 --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 300 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=36, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='False', forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=300, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue/epoch_150.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 151, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /DATA_SSD/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast1 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue/epoch_150.pth --batch 36 --latency_lambda 0 0 0 0 0 --forecast_num 1 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue --world_size 2 --nepoch 300 --forecast_loss False --forecast_model Baseline --encoder False --decoder True --port 10001 --log
Namespace(batch=36, binary=True, data='/DATA_SSD/zxlei/dataset/test/train', decoder='True', encoder='False', forecast_loss='False', forecast_model='Baseline', forecast_num=1, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast1', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue', lr=0.001, mode='train', model_only=False, nepoch=300, ngpus_per_node=2, nworker=0, only_det=True, port='10001', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/FalseTrue/epoch_150.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 151, lr: 0.001	epoch: 152, lr: 0.001	epoch: 153, lr: 0.001	epoch: 154, lr: 0.001	epoch: 155, lr: 0.001	Total loss 648.628967 (574.704538)	classifieion Loss 42.152592 (31.171081)	Localization Loss 606.476379 (543.533457)	Take 6940.644894361496 s
epoch: 156, lr: 0.001	epoch: 157, lr: 0.001	epoch: 158, lr: 0.001	epoch: 159, lr: 0.001	