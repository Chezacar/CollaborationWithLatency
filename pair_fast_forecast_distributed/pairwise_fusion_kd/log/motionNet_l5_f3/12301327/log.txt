GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 24 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder forecast classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/12301327 --world_size 6 --nepoch 400 --port 10026 --forecast_loss True --forecast_KD True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=24, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='False', encoder='False', forecast_KD='True', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/12301327', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'forecast', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 101, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 24 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder forecast classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/12301327 --world_size 6 --nepoch 400 --port 10026 --forecast_loss True --forecast_KD True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=24, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='False', encoder='False', forecast_KD='True', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/12301327', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'forecast', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 101, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth --batch 24 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder forecast classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/12301327 --world_size 6 --nepoch 400 --port 10026 --forecast_loss True --forecast_KD True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=24, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='False', encoder='False', forecast_KD='True', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/12301327', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/baseline/newraw/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'forecast', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 101, lr: 0.001	epoch: 102, lr: 0.001	epoch: 103, lr: 0.001	epoch: 104, lr: 0.001	epoch: 105, lr: 0.001	Total loss 409.765167 (545.220242)	classifieion Loss 1648.091064 (1466.478721)	Localization Loss 5345.866699 (4972.430674)	Forecast Loss 0.000000 (0.000000)	Take 598.4266848564148 s
epoch: 106, lr: 0.001	epoch: 107, lr: 0.001	epoch: 108, lr: 0.001	epoch: 109, lr: 0.001	epoch: 110, lr: 0.001	Total loss 406.561615 (512.313434)	classifieion Loss 1538.769531 (1588.254034)	Localization Loss 5403.672852 (5112.185217)	Forecast Loss 0.000000 (0.000000)	Take 599.6746571063995 s
epoch: 111, lr: 0.001	epoch: 112, lr: 0.001	epoch: 113, lr: 0.001	epoch: 114, lr: 0.001	epoch: 115, lr: 0.001	Total loss 400.196991 (493.954957)	classifieion Loss 1466.389404 (1633.614055)	Localization Loss 5334.788574 (5162.903225)	Forecast Loss 0.000000 (0.000000)	Take 599.098296880722 s
epoch: 116, lr: 0.001	epoch: 117, lr: 0.001	epoch: 118, lr: 0.001	epoch: 119, lr: 0.001	epoch: 120, lr: 0.001	Total loss 396.780029 (482.316776)	classifieion Loss 1476.984131 (1665.963381)	Localization Loss 5328.248047 (5185.916533)	Forecast Loss 0.000000 (0.000000)	Take 588.5867035388947 s
epoch: 121, lr: 0.001	epoch: 122, lr: 0.001	epoch: 123, lr: 0.001	epoch: 124, lr: 0.001	epoch: 125, lr: 0.001	Total loss 394.370453 (474.304782)	classifieion Loss 1484.884277 (1690.942116)	Localization Loss 5336.884766 (5209.962346)	Forecast Loss 0.000000 (0.000000)	Take 594.4068729877472 s
epoch: 126, lr: 0.001	epoch: 127, lr: 0.001	epoch: 128, lr: 0.001	epoch: 129, lr: 0.001	epoch: 130, lr: 0.001	Total loss 392.799744 (468.509830)	classifieion Loss 1485.902466 (1709.175203)	Localization Loss 5328.504883 (5227.632002)	Forecast Loss 0.000000 (0.000000)	Take 595.2213027477264 s
epoch: 131, lr: 0.001	epoch: 132, lr: 0.001	epoch: 133, lr: 0.001	epoch: 134, lr: 0.001	epoch: 135, lr: 0.001	Total loss 391.010254 (464.232448)	classifieion Loss 1501.262329 (1718.486844)	Localization Loss 5356.117188 (5240.146599)	Forecast Loss 0.000000 (0.000000)	Take 594.8210427761078 s
epoch: 136, lr: 0.001	epoch: 137, lr: 0.001	epoch: 138, lr: 0.001	epoch: 139, lr: 0.001	epoch: 140, lr: 0.001	Total loss 388.140869 (460.838126)	classifieion Loss 1523.432739 (1720.458381)	Localization Loss 5364.519531 (5250.388933)	Forecast Loss 0.000000 (0.000000)	Take 592.5557565689087 s
epoch: 141, lr: 0.001	epoch: 142, lr: 0.001	epoch: 143, lr: 0.001	epoch: 144, lr: 0.001	epoch: 145, lr: 0.001	Total loss 386.278503 (457.966423)	classifieion Loss 1543.943359 (1725.220521)	Localization Loss 5368.403809 (5260.300754)	Forecast Loss 0.000000 (0.000000)	Take 577.8595712184906 s
epoch: 146, lr: 0.001	epoch: 147, lr: 0.001	epoch: 148, lr: 0.001	epoch: 149, lr: 0.001	epoch: 150, lr: 0.001	Total loss 384.011871 (455.570219)	classifieion Loss 1557.181641 (1731.408987)	Localization Loss 5381.588867 (5269.432935)	Forecast Loss 0.000000 (0.000000)	Take 595.8669090270996 s
epoch: 151, lr: 0.001	epoch: 152, lr: 0.001	epoch: 153, lr: 0.001	epoch: 154, lr: 0.001	epoch: 155, lr: 0.001	Total loss 382.801971 (453.729870)	classifieion Loss 1585.537598 (1736.947010)	Localization Loss 5414.459473 (5280.430081)	Forecast Loss 0.000000 (0.000000)	Take 591.5246222019196 s
epoch: 156, lr: 0.001	epoch: 157, lr: 0.001	epoch: 158, lr: 0.001	epoch: 159, lr: 0.001	epoch: 160, lr: 0.001	Total loss 381.488495 (451.912886)	classifieion Loss 1613.542969 (1745.334091)	Localization Loss 5427.374512 (5291.957964)	Forecast Loss 0.000000 (0.000000)	Take 599.5600807666779 s
epoch: 161, lr: 0.001	epoch: 162, lr: 0.001	epoch: 163, lr: 0.001	epoch: 164, lr: 0.001	epoch: 165, lr: 0.001	Total loss 380.714294 (450.419212)	classifieion Loss 1629.472778 (1750.139911)	Localization Loss 5445.306152 (5301.908401)	Forecast Loss 0.000000 (0.000000)	Take 607.6970920562744 s
epoch: 166, lr: 0.001	epoch: 167, lr: 0.001	epoch: 168, lr: 0.001	epoch: 169, lr: 0.001	epoch: 170, lr: 0.001	Total loss 380.112274 (449.058329)	classifieion Loss 1639.010010 (1755.983066)	Localization Loss 5449.394531 (5310.615789)	Forecast Loss 0.000000 (0.000000)	Take 609.5727293491364 s
epoch: 171, lr: 0.001	epoch: 172, lr: 0.001	epoch: 173, lr: 0.001	epoch: 174, lr: 0.001	epoch: 175, lr: 0.001	Total loss 378.277954 (447.855186)	classifieion Loss 1638.478516 (1757.914791)	Localization Loss 5452.386719 (5315.585457)	Forecast Loss 0.000000 (0.000000)	Take 607.8020565509796 s
epoch: 176, lr: 0.001	epoch: 177, lr: 0.001	epoch: 178, lr: 0.001	epoch: 179, lr: 0.001	epoch: 180, lr: 0.001	Total loss 377.279816 (446.906090)	classifieion Loss 1664.550537 (1762.063105)	Localization Loss 5458.015625 (5322.576062)	Forecast Loss 0.000000 (0.000000)	Take 610.7823631763458 s
epoch: 181, lr: 0.001	epoch: 182, lr: 0.001	epoch: 183, lr: 0.001	epoch: 184, lr: 0.001	epoch: 185, lr: 0.001	Total loss 378.627716 (446.136808)	classifieion Loss 1658.834229 (1766.642893)	Localization Loss 5456.725586 (5330.717114)	Forecast Loss 0.000000 (0.000000)	Take 607.837203502655 s
epoch: 186, lr: 0.001	epoch: 187, lr: 0.001	epoch: 188, lr: 0.001	epoch: 189, lr: 0.001	epoch: 190, lr: 0.001	Total loss 377.781403 (445.273292)	classifieion Loss 1692.499512 (1768.608247)	Localization Loss 5482.851074 (5333.928120)	Forecast Loss 0.000000 (0.000000)	Take 606.4072270393372 s
epoch: 191, lr: 0.001	epoch: 192, lr: 0.001	epoch: 193, lr: 0.001	epoch: 194, lr: 0.001	epoch: 195, lr: 0.001	Total loss 375.920959 (444.799865)	classifieion Loss 1695.838867 (1769.726682)	Localization Loss 5493.063965 (5342.368225)	Forecast Loss 0.000000 (0.000000)	Take 596.3085548877716 s
epoch: 196, lr: 0.001	epoch: 197, lr: 0.001	epoch: 198, lr: 0.001	epoch: 199, lr: 0.001	epoch: 200, lr: 0.001	Total loss 491.653381 (952.671665)	classifieion Loss 1908.859497 (3825.639688)	Localization Loss 6606.847656 (8456.242312)	Forecast Loss 43930.976562 (46634.148438)	Take 613.9964551925659 s
epoch: 201, lr: 0.001	epoch: 202, lr: 0.001	epoch: 203, lr: 0.001	epoch: 204, lr: 0.001	epoch: 205, lr: 0.001	Total loss 489.606323 (786.889269)	classifieion Loss 1918.967041 (3178.066907)	Localization Loss 6605.947754 (7392.497607)	Forecast Loss 43930.976562 (46634.148438)	Take 608.1874196529388 s
epoch: 206, lr: 0.001	epoch: 207, lr: 0.001	epoch: 208, lr: 0.001	epoch: 209, lr: 0.001	epoch: 210, lr: 0.001	Total loss 487.020416 (776.744203)	classifieion Loss 1913.839966 (3220.323226)	Localization Loss 6570.471191 (7356.619111)	Forecast Loss 44806.539062 (46904.117188)	Take 599.3173935413361 s
epoch: 211, lr: 0.001	epoch: 212, lr: 0.001	epoch: 213, lr: 0.001	epoch: 214, lr: 0.001	epoch: 215, lr: 0.001	Total loss 487.427612 (763.490173)	classifieion Loss 1948.138794 (3255.660327)	Localization Loss 6575.307617 (7350.747146)	Forecast Loss 44806.539062 (46904.117188)	Take 603.6969735622406 s
epoch: 216, lr: 0.001	epoch: 217, lr: 0.001	epoch: 218, lr: 0.001	epoch: 219, lr: 0.001	epoch: 220, lr: 0.001	Total loss 493.373718 (753.182641)	classifieion Loss 1985.003784 (3281.913114)	Localization Loss 6585.357422 (7347.960171)	Forecast Loss 45159.921875 (46959.785156)	Take 608.4775295257568 s
epoch: 221, lr: 0.001	epoch: 222, lr: 0.001	epoch: 223, lr: 0.001	epoch: 224, lr: 0.001	epoch: 225, lr: 0.001	Total loss 491.764404 (728.467089)	classifieion Loss 1971.924316 (3224.674674)	Localization Loss 6587.995605 (7398.493262)	Forecast Loss 45159.921875 (46959.785156)	Take 607.7490260601044 s
epoch: 226, lr: 0.001	epoch: 227, lr: 0.001	epoch: 228, lr: 0.001	epoch: 229, lr: 0.001	epoch: 230, lr: 0.001	Total loss 486.009766 (720.148500)	classifieion Loss 2003.019531 (3234.188550)	Localization Loss 6606.307617 (7393.774487)	Forecast Loss 45432.386719 (46883.523438)	Take 611.8991153240204 s
epoch: 231, lr: 0.001	epoch: 232, lr: 0.001	epoch: 233, lr: 0.001	epoch: 234, lr: 0.001	GPU number: 6
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test1/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/12301327/epoch_200.pth --batch 24 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder forecast classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/12301327 --world_size 6 --nepoch 400 --port 10026 --forecast_loss True --forecast_KD True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=24, binary=True, data='/GPFS/data/zxlei/dataset/test1/train', decoder='False', encoder='False', forecast_KD='True', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/12301327', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/12301327/epoch_200.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'forecast', 'classification', 'regression'], visualization=True, world_size=6)

epoch: 201, lr: 0.001	epoch: 202, lr: 0.001	epoch: 203, lr: 0.001	epoch: 204, lr: 0.001	epoch: 205, lr: 0.001	Total loss 44028.519531 (46784.780234)	classifieion Loss 1972.409302 (3293.396400)	Localization Loss 6603.022461 (7361.004263)	Forecast Loss 43930.976562 (46634.148438)	Take 608.9684174060822 s
epoch: 206, lr: 0.001	epoch: 207, lr: 0.001	epoch: 208, lr: 0.001	epoch: 209, lr: 0.001	epoch: 210, lr: 0.001	Total loss 44903.593750 (47049.701445)	classifieion Loss 1998.781982 (3259.201808)	Localization Loss 6652.774414 (7396.068457)	Forecast Loss 44806.539062 (46904.117188)	Take 610.8766140937805 s
epoch: 211, lr: 0.001	epoch: 212, lr: 0.001	epoch: 213, lr: 0.001	epoch: 214, lr: 0.001	epoch: 215, lr: 0.001	Total loss 44900.480469 (47046.128398)	classifieion Loss 2000.986816 (3239.492886)	Localization Loss 6613.786133 (7391.183293)	Forecast Loss 44806.539062 (46904.117188)	Take 608.0103039741516 s
epoch: 216, lr: 0.001	epoch: 217, lr: 0.001	epoch: 218, lr: 0.001	epoch: 219, lr: 0.001	epoch: 220, lr: 0.001	Total loss 45255.996094 (47100.898125)	classifieion Loss 1971.538574 (3151.323431)	Localization Loss 6573.505859 (7352.778394)	Forecast Loss 45159.921875 (46959.785156)	Take 623.0924627780914 s
epoch: 221, lr: 0.001	epoch: 222, lr: 0.001	epoch: 223, lr: 0.001	epoch: 224, lr: 0.001	epoch: 225, lr: 0.001	Total loss 45254.218750 (47098.050625)	classifieion Loss 1965.827637 (3137.039254)	Localization Loss 6567.999023 (7265.779668)	Forecast Loss 45159.921875 (46959.785156)	Take 609.6531023979187 s
epoch: 226, lr: 0.001	epoch: 227, lr: 0.001	epoch: 228, lr: 0.001	epoch: 229, lr: 0.001	epoch: 230, lr: 0.001	Total loss 45525.937500 (47022.002773)	classifieion Loss 1967.591431 (3140.697255)	Localization Loss 6602.182129 (7277.641318)	Forecast Loss 45432.386719 (46883.523438)	Take 607.9589092731476 s
epoch: 231, lr: 0.001	epoch: 232, lr: 0.001	epoch: 233, lr: 0.001	epoch: 234, lr: 0.001	epoch: 235, lr: 0.001	Total loss 45525.031250 (47019.788906)	classifieion Loss 1939.065796 (3122.631173)	Localization Loss 6607.338867 (7205.067532)	Forecast Loss 45432.386719 (46883.523438)	Take 600.8518335819244 s
epoch: 236, lr: 0.001	epoch: 237, lr: 0.001	epoch: 238, lr: 0.001	epoch: 239, lr: 0.001	epoch: 240, lr: 0.001	Total loss 45377.773438 (46861.383828)	classifieion Loss 1873.549683 (3121.549818)	Localization Loss 6598.016113 (7175.502415)	Forecast Loss 45284.562500 (46724.312500)	Take 597.3282825946808 s
epoch: 241, lr: 0.001	epoch: 242, lr: 0.001	epoch: 243, lr: 0.001	epoch: 244, lr: 0.001	epoch: 245, lr: 0.001	Total loss 45376.847656 (46859.362969)	classifieion Loss 1886.400879 (3112.771843)	Localization Loss 6580.323730 (7141.855005)	Forecast Loss 45284.562500 (46724.312500)	Take 591.0478839874268 s
epoch: 246, lr: 0.001	epoch: 247, lr: 0.001	epoch: 248, lr: 0.001	epoch: 249, lr: 0.001	epoch: 250, lr: 0.001	Total loss 45216.398438 (46637.141289)	classifieion Loss 1941.267212 (3118.101449)	Localization Loss 6591.375000 (7177.831577)	Forecast Loss 45122.859375 (46500.820312)	Take 613.9040100574493 s
epoch: 251, lr: 0.001	epoch: 252, lr: 0.001	epoch: 253, lr: 0.001	epoch: 254, lr: 0.001	epoch: 255, lr: 0.001	Total loss 45215.074219 (46635.182422)	classifieion Loss 1944.941528 (3104.202522)	Localization Loss 6594.081055 (7155.700801)	Forecast Loss 45122.859375 (46500.820312)	Take 601.840413570404 s
epoch: 256, lr: 0.001	epoch: 257, lr: 0.001	epoch: 258, lr: 0.001	epoch: 259, lr: 0.001	epoch: 260, lr: 0.001	Total loss 44981.000000 (46387.816953)	classifieion Loss 1919.873779 (3101.642761)	Localization Loss 6567.664062 (7173.975171)	Forecast Loss 44889.339844 (46252.417969)	Take 605.3297564983368 s
epoch: 261, lr: 0.001	epoch: 262, lr: 0.001	epoch: 263, lr: 0.001	epoch: 264, lr: 0.001	epoch: 265, lr: 0.001	Total loss 44980.296875 (46385.873633)	classifieion Loss 1924.328979 (3099.455417)	Localization Loss 6648.400879 (7150.792539)	Forecast Loss 44889.339844 (46252.417969)	Take 607.7497324943542 s
epoch: 266, lr: 0.001	epoch: 267, lr: 0.001	epoch: 268, lr: 0.001	epoch: 269, lr: 0.001	epoch: 270, lr: 0.001	Total loss 44756.855469 (46142.511680)	classifieion Loss 1904.729492 (3093.147213)	Localization Loss 6576.094238 (7143.752554)	Forecast Loss 44664.855469 (46008.039062)	Take 594.3138699531555 s
epoch: 271, lr: 0.001	epoch: 272, lr: 0.001	epoch: 273, lr: 0.001	epoch: 274, lr: 0.001	epoch: 275, lr: 0.001	Total loss 44755.933594 (46140.715156)	classifieion Loss 1903.767090 (3081.432463)	Localization Loss 6576.367188 (7106.305764)	Forecast Loss 44664.855469 (46008.039062)	Take 594.890065908432 s
epoch: 276, lr: 0.001	epoch: 277, lr: 0.001	epoch: 278, lr: 0.001	epoch: 279, lr: 0.001	epoch: 280, lr: 0.001	Total loss 44574.703125 (45977.419648)	classifieion Loss 1877.921387 (3110.001563)	Localization Loss 6712.130859 (7177.115833)	Forecast Loss 44483.085938 (45843.558594)	Take 599.8052697181702 s
epoch: 281, lr: 0.001	epoch: 282, lr: 0.001	epoch: 283, lr: 0.001	epoch: 284, lr: 0.001	epoch: 285, lr: 0.001	Total loss 44574.328125 (45975.697617)	classifieion Loss 1888.023438 (3107.865065)	Localization Loss 6630.865234 (7119.196121)	Forecast Loss 44483.085938 (45843.558594)	Take 594.6997201442719 s
epoch: 286, lr: 0.001	epoch: 287, lr: 0.001	epoch: 288, lr: 0.001	epoch: 289, lr: 0.001	epoch: 290, lr: 0.001	Total loss 44399.640625 (45848.343828)	classifieion Loss 1949.703979 (3095.082614)	Localization Loss 6553.273438 (7094.926399)	Forecast Loss 44306.640625 (45715.039062)	Take 599.6380524635315 s
epoch: 291, lr: 0.001	epoch: 292, lr: 0.001	epoch: 293, lr: 0.001	epoch: 294, lr: 0.001	epoch: 295, lr: 0.001	Total loss 44397.367188 (45846.641719)	classifieion Loss 1940.125366 (3086.356763)	Localization Loss 6538.110840 (7094.883760)	Forecast Loss 44306.640625 (45715.039062)	Take 607.8912537097931 s
epoch: 296, lr: 0.001	epoch: 297, lr: 0.001	epoch: 298, lr: 0.001	epoch: 299, lr: 0.001	epoch: 300, lr: 0.001	Total loss 45119.093750 (46629.849219)	classifieion Loss 1928.332642 (3106.766785)	Localization Loss 6602.867676 (7164.417534)	Forecast Loss 45027.890625 (46496.773438)	Take 594.7532651424408 s
epoch: 301, lr: 0.001	epoch: 302, lr: 0.001	epoch: 303, lr: 0.001	epoch: 304, lr: 0.001	epoch: 305, lr: 0.001	Total loss 43862.441406 (46616.889687)	classifieion Loss 1897.074463 (3132.044131)	Localization Loss 6582.359375 (7198.102021)	Forecast Loss 43768.464844 (46482.707031)	Take 607.5854790210724 s
epoch: 306, lr: 0.001	epoch: 307, lr: 0.001	epoch: 308, lr: 0.001	epoch: 309, lr: 0.001	epoch: 310, lr: 0.001	Total loss 44291.113281 (46724.312539)	classifieion Loss 1947.482666 (3118.803438)	Localization Loss 6616.833008 (7163.139858)	Forecast Loss 44197.781250 (46590.859375)	Take 602.5108618736267 s
epoch: 311, lr: 0.001	epoch: 312, lr: 0.001	epoch: 313, lr: 0.001	epoch: 314, lr: 0.001	epoch: 315, lr: 0.001	Total loss 45137.441406 (46602.132969)	classifieion Loss 1859.808960 (3100.587094)	Localization Loss 6580.060059 (7139.561526)	Forecast Loss 45045.914062 (46470.550781)	Take 597.0998311042786 s
epoch: 316, lr: 0.001	epoch: 317, lr: 0.001	epoch: 318, lr: 0.001	epoch: 319, lr: 0.001	epoch: 320, lr: 0.001	Total loss 44939.273438 (46964.057305)	classifieion Loss 1902.659668 (3111.010050)	Localization Loss 6602.821289 (7160.453086)	Forecast Loss 44848.062500 (46832.238281)	Take 584.0814776420593 s
epoch: 321, lr: 0.001	epoch: 322, lr: 0.001	epoch: 323, lr: 0.001	epoch: 324, lr: 0.001	epoch: 325, lr: 0.001	Total loss 45334.445312 (46968.988281)	classifieion Loss 1941.551025 (3091.273856)	Localization Loss 6591.138672 (7102.478291)	Forecast Loss 45244.339844 (46838.058594)	Take 597.2007603645325 s
epoch: 326, lr: 0.001	epoch: 327, lr: 0.001	epoch: 328, lr: 0.001	epoch: 329, lr: 0.001	epoch: 330, lr: 0.001	Total loss 44398.613281 (46934.483359)	classifieion Loss 1912.185791 (3112.820643)	Localization Loss 6567.977539 (7122.371733)	Forecast Loss 44307.652344 (46803.093750)	Take 599.2456722259521 s
epoch: 331, lr: 0.001	epoch: 332, lr: 0.001	epoch: 333, lr: 0.001	epoch: 334, lr: 0.001	epoch: 335, lr: 0.001	Total loss 45355.171875 (47016.899023)	classifieion Loss 1950.604492 (3079.961766)	Localization Loss 6590.891602 (7039.172710)	Forecast Loss 45263.714844 (46886.722656)	Take 602.1464614868164 s
epoch: 336, lr: 0.001	epoch: 337, lr: 0.001	epoch: 338, lr: 0.001	epoch: 339, lr: 0.001	epoch: 340, lr: 0.001	Total loss 44709.019531 (46972.308477)	classifieion Loss 1947.014282 (3098.040745)	Localization Loss 6585.788086 (7113.645601)	Forecast Loss 44618.257812 (46841.617188)	Take 600.2232353687286 s
epoch: 341, lr: 0.001	epoch: 342, lr: 0.001	epoch: 343, lr: 0.001	epoch: 344, lr: 0.001	epoch: 345, lr: 0.001	Total loss 44283.792969 (45557.698359)	classifieion Loss 1908.175049 (3056.262618)	Localization Loss 6602.674805 (7052.076191)	Forecast Loss 44191.781250 (45425.609375)	Take 609.8065493106842 s
epoch: 346, lr: 0.001	epoch: 347, lr: 0.001	epoch: 348, lr: 0.001	epoch: 349, lr: 0.001	epoch: 350, lr: 0.001	Total loss 44353.218750 (46746.176016)	classifieion Loss 1930.417114 (3125.503009)	Localization Loss 6581.745117 (7100.137612)	Forecast Loss 44262.984375 (46615.574219)	Take 607.7815186977386 s
epoch: 351, lr: 0.001	epoch: 352, lr: 0.001	epoch: 353, lr: 0.001	epoch: 354, lr: 0.001	epoch: 355, lr: 0.001	Total loss 44022.355469 (46765.001523)	classifieion Loss 1999.721558 (3099.684434)	Localization Loss 6608.353027 (7074.384917)	Forecast Loss 43930.976562 (46634.980469)	Take 606.6871101856232 s
epoch: 356, lr: 0.001	epoch: 357, lr: 0.001	epoch: 358, lr: 0.001	epoch: 359, lr: 0.001	epoch: 360, lr: 0.001	Total loss 44861.468750 (46179.616211)	classifieion Loss 1936.649902 (3051.480547)	Localization Loss 6642.837891 (7030.282805)	Forecast Loss 44771.230469 (46050.105469)	Take 596.5227179527283 s
epoch: 361, lr: 0.001	epoch: 362, lr: 0.001	epoch: 363, lr: 0.001	epoch: 364, lr: 0.001	epoch: 365, lr: 0.001	Total loss 44933.226562 (47009.233281)	classifieion Loss 1947.730835 (3095.814587)	Localization Loss 6602.031250 (7068.407219)	Forecast Loss 44843.359375 (46879.859375)	Take 596.9476342201233 s
epoch: 366, lr: 0.001	epoch: 367, lr: 0.001	epoch: 368, lr: 0.001	epoch: 369, lr: 0.001	epoch: 370, lr: 0.001	Total loss 44480.386719 (46862.300742)	classifieion Loss 2014.416016 (3097.647849)	Localization Loss 6620.848145 (7073.148257)	Forecast Loss 44390.167969 (46732.750000)	Take 600.5317575931549 s
epoch: 371, lr: 0.001	epoch: 372, lr: 0.001	epoch: 373, lr: 0.001	epoch: 374, lr: 0.001	epoch: 375, lr: 0.001	Total loss 44740.621094 (45885.079883)	classifieion Loss 1919.623047 (3056.654192)	Localization Loss 6636.168457 (7023.485542)	Forecast Loss 44649.882812 (45755.425781)	Take 605.5341017246246 s
epoch: 376, lr: 0.001	epoch: 377, lr: 0.001	epoch: 378, lr: 0.001	epoch: 379, lr: 0.001	epoch: 380, lr: 0.001	Total loss 44089.648438 (46757.274961)	classifieion Loss 1919.813477 (3105.218932)	Localization Loss 6637.612305 (7056.635105)	Forecast Loss 43999.996094 (46627.937500)	Take 611.1130564212799 s
epoch: 381, lr: 0.001	epoch: 382, lr: 0.001	epoch: 383, lr: 0.001	epoch: 384, lr: 0.001	epoch: 385, lr: 0.001	Total loss 44816.957031 (46968.952695)	classifieion Loss 1943.892944 (3081.296438)	Localization Loss 6592.216309 (7047.031829)	Forecast Loss 44726.699219 (46840.363281)	Take 602.4946184158325 s
epoch: 386, lr: 0.001	epoch: 387, lr: 0.001	epoch: 388, lr: 0.001	epoch: 389, lr: 0.001	