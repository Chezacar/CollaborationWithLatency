GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 12 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10053 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=12, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10053', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	epoch: 102, lr: 0.001	epoch: 103, lr: 0.001	epoch: 104, lr: 0.001	epoch: 105, lr: 0.001	Total loss 4140.102539 (3372.214466)	classifieion Loss 273.354248 (160.071389)	Localization Loss 1928.700562 (1510.027001)	Forecast Loss 1938.047729 (1702.115356)	Take 1829.082832813263 s
epoch: 106, lr: 0.001	epoch: 107, lr: 0.001	epoch: 108, lr: 0.001	epoch: 109, lr: 0.001	epoch: 110, lr: 0.001	Total loss 3193.753906 (2621.445144)	classifieion Loss 203.052124 (119.930930)	Localization Loss 1429.933594 (1185.240318)	Forecast Loss 1560.768066 (1316.274414)	Take 1972.0707788467407 s
epoch: 111, lr: 0.001	epoch: 112, lr: 0.001	epoch: 113, lr: 0.001	epoch: 114, lr: 0.001	epoch: 115, lr: 0.001	Total loss 2689.769043 (2280.678815)	classifieion Loss 147.753937 (103.441075)	Localization Loss 1222.462646 (1046.501239)	Forecast Loss 1319.552368 (1130.736816)	Take 1898.7469630241394 s
epoch: 116, lr: 0.001	epoch: 117, lr: 0.001	epoch: 118, lr: 0.001	epoch: 119, lr: 0.001	epoch: 120, lr: 0.001	Total loss 2449.264893 (2154.659818)	classifieion Loss 119.603073 (95.440943)	Localization Loss 1112.686768 (998.569437)	Forecast Loss 1216.975098 (1060.649292)	Take 1578.5762696266174 s
epoch: 121, lr: 0.001	epoch: 122, lr: 0.001	epoch: 123, lr: 0.001	epoch: 124, lr: 0.001	epoch: 125, lr: 0.001	Total loss 2265.949219 (1913.000079)	classifieion Loss 110.976738 (82.404361)	Localization Loss 1015.379822 (891.096200)	Forecast Loss 1139.592529 (939.499512)	Take 1682.2592854499817 s
epoch: 126, lr: 0.001	epoch: 127, lr: 0.001	epoch: 128, lr: 0.001	epoch: 129, lr: 0.001	epoch: 130, lr: 0.001	Total loss 2312.100098 (1801.236515)	classifieion Loss 118.451660 (76.119138)	Localization Loss 1144.770264 (839.540248)	Forecast Loss 1048.878052 (885.577087)	Take 1657.113303899765 s
epoch: 131, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 24 --log --latency_lambda 5 5 5 5 5 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10022 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=24, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10022', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', visualization=True, world_size=2)

epoch: 101, lr: 0.001	epoch: 132, lr: 0.001	epoch: 102, lr: 0.001	epoch: 133, lr: 0.001	epoch: 103, lr: 0.001	epoch: 134, lr: 0.001	epoch: 104, lr: 0.001	epoch: 135, lr: 0.001	epoch: 105, lr: 0.001	Total loss 1973.657471 (1710.327024)	classifieion Loss 77.937424 (71.378915)	Localization Loss 875.793457 (801.438873)	Forecast Loss 1019.926575 (837.509338)	Take 2168.980727672577 s
epoch: 136, lr: 0.001	Total loss 3972.852539 (3580.162120)	classifieion Loss 213.464767 (171.294900)	Localization Loss 1708.873901 (1572.225847)	Forecast Loss 2050.513916 (1836.641113)	Take 2233.7535343170166 s
epoch: 106, lr: 0.001	epoch: 137, lr: 0.001	epoch: 107, lr: 0.001	epoch: 138, lr: 0.001	epoch: 108, lr: 0.001	epoch: 139, lr: 0.001	epoch: 109, lr: 0.001	epoch: 140, lr: 0.001	epoch: 110, lr: 0.001	Total loss 1766.495361 (1637.504754)	classifieion Loss 53.500698 (66.580974)	Localization Loss 762.832153 (770.436902)	Forecast Loss 950.162537 (800.486389)	Take 2121.5336685180664 s
epoch: 141, lr: 0.001	Total loss 3080.812500 (2857.269188)	classifieion Loss 149.405182 (129.023081)	Localization Loss 1341.718506 (1227.558425)	Forecast Loss 1589.688721 (1500.687744)	Take 2147.8477222919464 s
epoch: 111, lr: 0.001	epoch: 142, lr: 0.001	epoch: 112, lr: 0.001	epoch: 143, lr: 0.001	epoch: 113, lr: 0.001	epoch: 144, lr: 0.001	epoch: 114, lr: 0.001	epoch: 145, lr: 0.001	epoch: 115, lr: 0.001	Total loss 1806.541016 (1568.593952)	classifieion Loss 61.876781 (63.382096)	Localization Loss 803.386963 (729.845062)	Forecast Loss 941.277283 (775.367065)	Take 2162.911176919937 s
epoch: 146, lr: 0.001	Total loss 2754.418945 (2490.053059)	classifieion Loss 125.624016 (110.465428)	Localization Loss 1202.561401 (1087.412696)	Forecast Loss 1426.233521 (1292.174683)	Take 2187.708371400833 s
epoch: 116, lr: 0.001	epoch: 147, lr: 0.001	epoch: 117, lr: 0.001	epoch: 148, lr: 0.001	epoch: 118, lr: 0.001	epoch: 149, lr: 0.001	epoch: 119, lr: 0.001	epoch: 150, lr: 0.001	epoch: 120, lr: 0.001	Total loss 1781.103882 (1514.819820)	classifieion Loss 67.327286 (60.225216)	Localization Loss 806.244263 (709.336021)	Forecast Loss 907.532349 (745.259155)	Take 2129.8726422786713 s
epoch: 151, lr: 0.001	Total loss 2235.321777 (2161.233369)	classifieion Loss 93.811340 (95.402603)	Localization Loss 936.283386 (963.053660)	Forecast Loss 1205.227051 (1102.777344)	Take 2156.9522156715393 s
epoch: 121, lr: 0.001	epoch: 152, lr: 0.001	epoch: 122, lr: 0.001	epoch: 153, lr: 0.001	epoch: 123, lr: 0.001	epoch: 154, lr: 0.001	epoch: 124, lr: 0.001	epoch: 155, lr: 0.001	epoch: 125, lr: 0.001	Total loss 1776.801270 (1503.476657)	classifieion Loss 44.634209 (58.674186)	Localization Loss 818.333679 (713.041531)	Forecast Loss 913.833313 (731.761047)	Take 2243.0277619361877 s
epoch: 156, lr: 0.001	Total loss 2140.088135 (1983.274219)	classifieion Loss 102.553391 (87.511037)	Localization Loss 948.203003 (899.807529)	Forecast Loss 1089.331787 (995.955872)	Take 2255.288210630417 s
epoch: 126, lr: 0.001	epoch: 157, lr: 0.001	epoch: 127, lr: 0.001	epoch: 158, lr: 0.001	epoch: 128, lr: 0.001	epoch: 159, lr: 0.001	epoch: 129, lr: 0.001	epoch: 160, lr: 0.001	epoch: 130, lr: 0.001	Total loss 1840.900024 (1425.716572)	classifieion Loss 58.350838 (54.769210)	Localization Loss 813.001099 (663.423642)	Forecast Loss 969.548096 (707.523865)	Take 1751.964370727539 s
epoch: 161, lr: 0.001	Total loss 2098.991699 (2047.807457)	classifieion Loss 76.124649 (88.351991)	Localization Loss 918.326355 (917.596338)	Forecast Loss 1104.540649 (1041.859375)	Take 1895.349532842636 s
epoch: 131, lr: 0.001	epoch: 162, lr: 0.001	epoch: 163, lr: 0.001	epoch: 132, lr: 0.001	epoch: 164, lr: 0.001	epoch: 133, lr: 0.001	epoch: 165, lr: 0.001	epoch: 134, lr: 0.001	Total loss 1658.400513 (1415.168120)	classifieion Loss 62.903893 (53.397310)	Localization Loss 742.251221 (665.184630)	Forecast Loss 853.245422 (696.585815)	Take 1820.372742652893 s
epoch: 135, lr: 0.001	epoch: 166, lr: 0.001	epoch: 167, lr: 0.001	Total loss 1994.816895 (1843.811525)	classifieion Loss 94.068802 (79.197795)	Localization Loss 893.100464 (834.758223)	Forecast Loss 1007.647644 (929.855530)	Take 1819.292228937149 s
epoch: 136, lr: 0.001	epoch: 168, lr: 0.001	epoch: 137, lr: 0.001	epoch: 169, lr: 0.001	epoch: 138, lr: 0.001	epoch: 170, lr: 0.001	epoch: 139, lr: 0.001	Total loss 1513.113647 (1381.174615)	classifieion Loss 33.342407 (51.444515)	Localization Loss 636.842285 (650.084817)	Forecast Loss 842.928955 (679.645203)	Take 1794.299230337143 s
epoch: 140, lr: 0.001	epoch: 171, lr: 0.001	epoch: 172, lr: 0.001	Total loss 1808.522583 (1749.616715)	classifieion Loss 68.928360 (73.329129)	Localization Loss 775.954956 (793.918181)	Forecast Loss 963.639282 (882.369690)	Take 1799.871101617813 s
epoch: 141, lr: 0.001	epoch: 173, lr: 0.001	epoch: 142, lr: 0.001	epoch: 174, lr: 0.001	epoch: 143, lr: 0.001	epoch: 175, lr: 0.001	epoch: 144, lr: 0.001	Total loss 1420.181641 (1338.797615)	classifieion Loss 41.645931 (49.675503)	Localization Loss 618.612793 (621.400801)	Forecast Loss 759.922974 (667.721130)	Take 1790.891063451767 s
epoch: 145, lr: 0.001	epoch: 176, lr: 0.001	epoch: 177, lr: 0.001	Total loss 1755.729004 (1668.926325)	classifieion Loss 64.660881 (69.223808)	Localization Loss 799.993896 (755.610395)	Forecast Loss 891.074158 (844.092285)	Take 1815.6178851127625 s
epoch: 146, lr: 0.001	epoch: 178, lr: 0.001	epoch: 147, lr: 0.001	epoch: 148, lr: 0.001	epoch: 179, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 8 --log --latency_lambda 0 0 0 0 0 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 8 --log --latency_lambda 0 0 0 0 0 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	epoch: 149, lr: 0.001	epoch: 150, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 8 --log --latency_lambda 0 0 0 0 0 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	Total loss 1701.271729 (1807.330114)	classifieion Loss 58.030823 (73.674171)	Localization Loss 734.762207 (810.693913)	Forecast Loss 908.478699 (922.961975)	Take 1624.841647863388 s
epoch: 151, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 8 --log --latency_lambda 0 0 0 0 0 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	epoch: 152, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 8 --log --latency_lambda 0 0 0 0 0 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 8 --log --latency_lambda 0 0 0 0 0 --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model Baseline --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='Baseline', forecast_num=3, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 8 --log --latency_lambda 0 0 0 0 0 --utp encoder decoder classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model Baseline --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='Baseline', forecast_num=3, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	epoch: 153, lr: 0.001	epoch: 154, lr: 0.001	epoch: 155, lr: 0.001	Total loss 1646.700806 (1559.694187)	classifieion Loss 53.821709 (63.728269)	Localization Loss 741.877319 (705.095614)	Forecast Loss 851.001770 (790.869873)	Take 1324.7098805904388 s
epoch: 156, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 8 --log --latency_lambda 0 0 0 0 0 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 8 --log --latency_lambda 0 0 0 0 0 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 8 --log --latency_lambda 0 0 0 0 0 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[0, 0, 0, 0, 0], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	epoch: 157, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 8 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 8 --log --latency_lambda 10 10 10 10 10 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=8, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[10, 10, 10, 10, 10], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	epoch: 158, lr: 0.001	epoch: 159, lr: 0.001	epoch: 160, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 12 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=12, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 18 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=18, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 18 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=18, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	GPU number: 2
command line: --mode train --lr 0.001 --data /GPFS/data/zxlei/dataset/test/train --nworker 0 --layer 3 --logname latency5forecast3 --resume /DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth --batch 16 --log --latency_lambda 5 5 5 5 5 --utp encoder decoder adafusion classification regression --forecast_num 3 --logpath /GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130 --world_size 2 --nepoch 400 --port 10026 --forecast_loss True --encoder False --decode False --forecast_model MotionNet --log
Namespace(batch=16, binary=True, data='/GPFS/data/zxlei/dataset/test/train', decoder='False', encoder='False', forecast_loss='True', forecast_model='MotionNet', forecast_num=3, gpu=2, kd=100000, latency_lambda=[5, 5, 5, 5, 5], layer=3, load_model='None', log=True, logname='latency5forecast3', logpath='/GPFS/data/zxlei/CollaborativePerception/Forcast/LatencyVersion/pair_fast_forecast_distributed/pairwise_fusion_kd/log/motionNet_l5_f3/11271130', lr=0.001, mode='train', model_only=False, nepoch=400, ngpus_per_node=2, nworker=0, only_det=True, port='10026', rank=0, resume='/DB/rhome/slren/data_gpfs/log/train_single_seq/2021-09-05_22-06-09/epoch_100.pth', resume_teacher='/DATA_SSD/slren/teacher_aug_batch_4_epoch_100.pth', utp=['encoder', 'decoder', 'adafusion', 'classification', 'regression'], visualization=True, world_size=2)

epoch: 101, lr: 0.001	epoch: 102, lr: 0.001	Total loss 1591.025024 (1495.942439)	classifieion Loss 53.814770 (58.878285)	Localization Loss 687.806824 (678.363910)	Forecast Loss 849.403442 (758.699890)	Take 1939.677081823349 s
epoch: 161, lr: 0.001	epoch: 103, lr: 0.001	epoch: 104, lr: 0.001	epoch: 105, lr: 0.001	Total loss 2113.658447 (1638.055529)	classifieion Loss 2516.323730 (2163.530219)	Localization Loss 26267.140625 (23454.247090)	Forecast Loss 2113.658447 (1638.055420)	Take 467.8526704311371 s
epoch: 106, lr: 0.001	epoch: 162, lr: 0.001	epoch: 107, lr: 0.001	epoch: 108, lr: 0.001	epoch: 109, lr: 0.001	epoch: 110, lr: 0.001	epoch: 163, lr: 0.001	Total loss 1738.276367 (1234.974255)	classifieion Loss 2477.590820 (1922.001915)	Localization Loss 25088.597656 (22273.161641)	Forecast Loss 1738.276367 (1234.974365)	Take 501.6774022579193 s
epoch: 111, lr: 0.001	epoch: 112, lr: 0.001	epoch: 113, lr: 0.001	epoch: 164, lr: 0.001	epoch: 114, lr: 0.001	epoch: 115, lr: 0.001	Total loss 1481.056030 (1013.359063)	classifieion Loss 2399.427734 (1868.645125)	Localization Loss 24707.923828 (21953.729954)	Forecast Loss 1481.056030 (1013.359070)	Take 542.3753545284271 s
epoch: 116, lr: 0.001	epoch: 117, lr: 0.001	epoch: 165, lr: 0.001	epoch: 118, lr: 0.001	epoch: 119, lr: 0.001	epoch: 120, lr: 0.001	Total loss 1202.358521 (843.976734)	classifieion Loss 2073.406250 (1743.787421)	Localization Loss 24525.558594 (21849.274701)	Forecast Loss 1202.358521 (843.976868)	Take 548.092946767807 s
epoch: 121, lr: 0.001	Total loss 1552.901733 (1469.263538)	classifieion Loss 49.365185 (56.766593)	Localization Loss 661.608032 (669.752250)	Forecast Loss 841.928528 (742.744995)	Take 1903.0497934818268 s
epoch: 166, lr: 0.001	epoch: 122, lr: 0.001	epoch: 123, lr: 0.001	epoch: 124, lr: 0.001	epoch: 167, lr: 0.001	epoch: 125, lr: 0.001	Total loss 1200.507568 (748.951111)	classifieion Loss 2446.687988 (1671.854327)	Localization Loss 24199.662109 (21779.742454)	Forecast Loss 1200.507568 (748.951355)	Take 546.0223321914673 s
epoch: 126, lr: 0.001	epoch: 127, lr: 0.001	epoch: 128, lr: 0.001	epoch: 168, lr: 0.001	epoch: 129, lr: 0.001	epoch: 130, lr: 0.001	Total loss 1069.316162 (688.036611)	classifieion Loss 2423.878906 (1635.334997)	Localization Loss 24034.148438 (21746.519824)	Forecast Loss 1069.316162 (688.036560)	Take 542.2173671722412 s
epoch: 131, lr: 0.001	epoch: 169, lr: 0.001	epoch: 132, lr: 0.001	epoch: 133, lr: 0.001	epoch: 134, lr: 0.001	epoch: 135, lr: 0.001	epoch: 170, lr: 0.001	Total loss 933.158081 (626.378939)	classifieion Loss 1811.497559 (1562.267507)	Localization Loss 23881.291016 (21715.205273)	Forecast Loss 933.158081 (626.379028)	Take 556.0945456027985 s
epoch: 136, lr: 0.001	epoch: 137, lr: 0.001	epoch: 138, lr: 0.001	epoch: 139, lr: 0.001	Total loss 1509.569824 (1417.128938)	classifieion Loss 53.761059 (54.150212)	Localization Loss 663.632202 (648.317373)	Forecast Loss 792.176575 (714.661438)	Take 2150.93097615242 s
epoch: 171, lr: 0.001	epoch: 140, lr: 0.001	Total loss 935.040466 (590.305363)	classifieion Loss 2272.682617 (1519.933184)	Localization Loss 24234.400391 (21648.422660)	Forecast Loss 935.040466 (590.305359)	Take 585.6757955551147 s
epoch: 141, lr: 0.001	epoch: 142, lr: 0.001	epoch: 143, lr: 0.001	epoch: 172, lr: 0.001	epoch: 144, lr: 0.001	epoch: 145, lr: 0.001	Total loss 762.760010 (554.216840)	classifieion Loss 1712.549072 (1505.621679)	Localization Loss 23848.210938 (21654.515072)	Forecast Loss 762.760010 (554.216858)	Take 570.7295005321503 s
epoch: 146, lr: 0.001	epoch: 173, lr: 0.001	epoch: 147, lr: 0.001	epoch: 148, lr: 0.001	epoch: 149, lr: 0.001	epoch: 150, lr: 0.001	Total loss 844.518555 (520.930606)	classifieion Loss 1808.433105 (1493.441973)	Localization Loss 23826.978516 (21634.257891)	Forecast Loss 844.518555 (520.930664)	Take 496.7681529521942 s
epoch: 151, lr: 0.001	epoch: 174, lr: 0.001	epoch: 152, lr: 0.001	epoch: 153, lr: 0.001	epoch: 154, lr: 0.001	epoch: 155, lr: 0.001	epoch: 175, lr: 0.001	Total loss 691.827820 (502.788806)	classifieion Loss 2057.446533 (1489.528576)	Localization Loss 24114.792969 (21634.300658)	Forecast Loss 691.827820 (502.788696)	Take 474.6103436946869 s
epoch: 156, lr: 0.001	epoch: 157, lr: 0.001	epoch: 158, lr: 0.001	epoch: 159, lr: 0.001	epoch: 160, lr: 0.001	Total loss 1564.813965 (1398.631081)	classifieion Loss 48.867809 (52.458222)	Localization Loss 709.075073 (640.688456)	Forecast Loss 806.871155 (705.484314)	Take 2228.1702632904053 s
epoch: 176, lr: 0.001	Total loss 889.203552 (477.004426)	classifieion Loss 2422.314453 (1488.778317)	Localization Loss 23965.597656 (21621.876999)	Forecast Loss 889.203552 (477.004425)	Take 490.0532155036926 s
epoch: 161, lr: 0.001	epoch: 162, lr: 0.001	epoch: 163, lr: 0.001	epoch: 164, lr: 0.001	epoch: 177, lr: 0.001	epoch: 165, lr: 0.001	Total loss 679.479858 (472.332488)	classifieion Loss 1825.122681 (1475.003901)	Localization Loss 23816.652344 (21620.889408)	Forecast Loss 679.479858 (472.332458)	Take 488.2200093269348 s
epoch: 166, lr: 0.001	epoch: 167, lr: 0.001	epoch: 168, lr: 0.001	epoch: 169, lr: 0.001	epoch: 178, lr: 0.001	epoch: 170, lr: 0.001	Total loss 650.494080 (453.461038)	classifieion Loss 1911.270020 (1486.632410)	Localization Loss 23817.326172 (21612.218955)	Forecast Loss 650.494080 (453.460938)	Take 488.8714828491211 s
epoch: 171, lr: 0.001	epoch: 172, lr: 0.001	epoch: 173, lr: 0.001	epoch: 174, lr: 0.001	epoch: 179, lr: 0.001	epoch: 175, lr: 0.001	Total loss 735.226318 (437.442464)	classifieion Loss 1854.018311 (1465.291580)	Localization Loss 23587.003906 (21582.509258)	Forecast Loss 735.226318 (437.442505)	Take 487.93645668029785 s
epoch: 176, lr: 0.001	epoch: 177, lr: 0.001	epoch: 178, lr: 0.001	epoch: 180, lr: 0.001	epoch: 179, lr: 0.001	epoch: 180, lr: 0.001	Total loss 594.882996 (430.258108)	classifieion Loss 1840.097168 (1452.707846)	Localization Loss 23814.644531 (21561.591849)	Forecast Loss 594.882996 (430.258057)	Take 490.85670018196106 s
epoch: 181, lr: 0.001	epoch: 182, lr: 0.001	epoch: 183, lr: 0.001	Total loss 1581.540649 (1355.001682)	classifieion Loss 52.259315 (51.547470)	Localization Loss 709.400024 (618.076458)	Forecast Loss 819.881287 (685.377747)	Take 2292.4774746894836 s
epoch: 181, lr: 0.001	epoch: 184, lr: 0.001	epoch: 185, lr: 0.001	Total loss 521.918396 (423.594939)	classifieion Loss 1775.435181 (1464.941635)	Localization Loss 23683.667969 (21560.078652)	Forecast Loss 521.918396 (423.594727)	Take 482.52285623550415 s
epoch: 186, lr: 0.001	epoch: 187, lr: 0.001	epoch: 182, lr: 0.001	epoch: 188, lr: 0.001	epoch: 189, lr: 0.001	epoch: 190, lr: 0.001	